{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc187cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d69401ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c613983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cf58dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0af34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.par_with_attr import ParWithAttr\n",
    "from model.base_par import DepParser\n",
    "from utils import uas_las, to_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b6ba4",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cff15ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # domains = ['BC', 'FIN', 'LEG', 'PB', 'PC', 'ZX']\n",
    "    domains = ['BC']\n",
    "    # plm = 'hfl/chinese-electra-180g-large-discriminator'\n",
    "    plm = 'hfl/chinese-electra-180g-base-discriminator'\n",
    "    data_file = '../data_testset/1to800_1108.json'\n",
    "    random_seed = 42\n",
    "    num_epochs = 15\n",
    "    batch_size = 128\n",
    "    lr = 2e-5\n",
    "    weight_decay = 0.01\n",
    "    dropout = 0.2\n",
    "    grad_clip = 2\n",
    "    scheduler = 'linear'\n",
    "    warmup_ratio = 0.1\n",
    "    num_early_stop = 3\n",
    "    max_length = 160\n",
    "    hidden_size = 400\n",
    "    num_labels = 35\n",
    "    gamma = 0.7\n",
    "    alpha = 0.7\n",
    "    print_every = 400\n",
    "    eval_every = 800\n",
    "    cuda = True\n",
    "    fp16 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ced03d",
   "metadata": {},
   "source": [
    "# Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "305825ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = CFG.domains\n",
    "\n",
    "tags, rels = [], []\n",
    "for domain in domains:\n",
    "    # file = f'suda/train/{domain}-Train-full.conll'\n",
    "    file = '../aug/codt/codt_train.conll'\n",
    "    fp = open(file, encoding='utf-8')\n",
    "    for line in fp.readlines():\n",
    "        # another sentence\n",
    "        if line == '\\n':\n",
    "            continue\n",
    "        line_sp = line.split('\\t')\n",
    "        rels.append(line_sp[7])\n",
    "        tags.append(line_sp[3])\n",
    "    \n",
    "    fp.close()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae03c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_dct = {\n",
    "    'root': '根节点',\n",
    "    'sasubj-obj': '同主同宾',\n",
    "    'sasubj': '同主语',\n",
    "    'dfsubj': '不同主语',\n",
    "    'subj': '主语',\n",
    "    'subj-in': '内部主语',\n",
    "    'obj': '宾语',\n",
    "    'pred': '谓语',\n",
    "    'att': '定语',\n",
    "    'adv': '状语',\n",
    "    'cmp': '补语',\n",
    "    'coo': '并列',\n",
    "    'pobj': '介宾',\n",
    "    'iobj': '间宾',\n",
    "    'de': '的',\n",
    "    'adjct': '附加',\n",
    "    'app': '称呼',\n",
    "    'exp': '解释',\n",
    "    'punc': '标点',\n",
    "    'frag': '片段',\n",
    "    'repet': '重复',\n",
    "    # rst\n",
    "    'attr': '归属',\n",
    "    'bckg': '背景',\n",
    "    'cause': '因果',\n",
    "    'comp': '比较',\n",
    "    'cond': '状况',\n",
    "    'cont': '对比',\n",
    "    'elbr': '阐述',\n",
    "    'enbm': '目的',\n",
    "    'eval': '评价',\n",
    "    'expl': '解释-例证',\n",
    "    'joint': '联合',\n",
    "    'manner': '方式',\n",
    "    'rstm': '重申',\n",
    "    'temp': '时序',\n",
    "    # 'tp-chg': '主题变更',\n",
    "    # 'prob-sol': '问题-解决',\n",
    "    # 'qst-ans': '疑问-回答',\n",
    "    # 'stm-rsp': '陈述-回应',\n",
    "    # 'req-proc': '需求-处理',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77dbbfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'root': 0, 'sasubj-obj': 1, 'sasubj': 2, 'dfsubj': 3, 'subj': 4, 'subj-in': 5, 'obj': 6, 'pred': 7, 'att': 8, 'adv': 9, 'cmp': 10, 'coo': 11, 'pobj': 12, 'iobj': 13, 'de': 14, 'adjct': 15, 'app': 16, 'exp': 17, 'punc': 18, 'frag': 19, 'repet': 20, 'attr': 21, 'bckg': 22, 'cause': 23, 'comp': 24, 'cond': 25, 'cont': 26, 'elbr': 27, 'enbm': 28, 'eval': 29, 'expl': 30, 'joint': 31, 'manner': 32, 'rstm': 33, 'temp': 34}\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "rel2id = {}\n",
    "for i, (key, value) in enumerate(rel_dct.items()):\n",
    "    rel2id[key] = i\n",
    "print(rel2id)\n",
    "print(len(rel2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae77b7b2",
   "metadata": {},
   "source": [
    "# Seed & Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c579a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=CFG.random_seed):\n",
    "    np.random.seed(seed%(2**32-1))\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic =True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "636d4a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a633a3d",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc634b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dependency():\n",
    "    def __init__(self, idx, word, head, rel):\n",
    "        self.id = idx\n",
    "        self.word = word\n",
    "        self.head = head\n",
    "        self.rel = rel\n",
    "\n",
    "    def __str__(self):\n",
    "        # example:  1\t上海\t_\tNR\tNR\t_\t2\tnn\t_\t_\n",
    "        values = [str(self.idx), self.word, \"_\", \"_\", \"_\", \"_\", str(self.head), self.rel, \"_\", \"_\"]\n",
    "        return '\\t'.join(values)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"({self.word}, {self.head}, {self.rel})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7482312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG.plm)\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5fa36cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rel</th>\n",
       "      <th>rel_name</th>\n",
       "      <th>attribute</th>\n",
       "      <th>example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>根节点</td>\n",
       "      <td>一个句子的根节点，是句子的核心事件的中心词（一般是谓词），如果没有核心，则第一个主要谓语作为...</td>\n",
       "      <td>“你好，我想咨询一下”中，“咨询”是这个句子的核心，而“你 好”只是一句问候语，因此从“咨询...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sasubj-obj</td>\n",
       "      <td>同主语同宾语</td>\n",
       "      <td>两个谓语（一般为两个动词并列）共享主语和宾语，允许主语完全省略。</td>\n",
       "      <td>“有什么问题我能帮你处理或解决呢？”中，“处理”和“解决”的主语都是“我”，宾语是“问题”，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sasubj</td>\n",
       "      <td>同主语</td>\n",
       "      <td>两个谓语共享主语，但是都是不及物动词或具有不同的宾语，允许主语完全省略。</td>\n",
       "      <td>“我帮你问一下”，“帮”和“问”的主语都是我，但显然宾语不同，因此由第一个谓词“帮”发射“同...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dfsubj</td>\n",
       "      <td>不同主语</td>\n",
       "      <td>两个谓语的主语不同。</td>\n",
       "      <td>“你把订单号发一下，我查询一下”，“发”和“查询”就是由不同主语所发出的动作，因此，由“发”...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>subj</td>\n",
       "      <td>主语</td>\n",
       "      <td>主语是谓语动作的发出者，或是谓语动词的承受对象，或谓语是对主语的状态或其他情况的描述。主语通...</td>\n",
       "      <td>“我买了洗衣液”，“我”是“买”这个动作的主体对象，因此由“买”发射一条“主语”弧到“我”。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         rel rel_name  \\\n",
       "0      0        root      根节点   \n",
       "1      1  sasubj-obj   同主语同宾语   \n",
       "2      2      sasubj      同主语   \n",
       "3      3      dfsubj     不同主语   \n",
       "4      4        subj       主语   \n",
       "\n",
       "                                           attribute  \\\n",
       "0  一个句子的根节点，是句子的核心事件的中心词（一般是谓词），如果没有核心，则第一个主要谓语作为...   \n",
       "1                   两个谓语（一般为两个动词并列）共享主语和宾语，允许主语完全省略。   \n",
       "2               两个谓语共享主语，但是都是不及物动词或具有不同的宾语，允许主语完全省略。   \n",
       "3                                         两个谓语的主语不同。   \n",
       "4  主语是谓语动作的发出者，或是谓语动词的承受对象，或谓语是对主语的状态或其他情况的描述。主语通...   \n",
       "\n",
       "                                             example  \n",
       "0  “你好，我想咨询一下”中，“咨询”是这个句子的核心，而“你 好”只是一句问候语，因此从“咨询...  \n",
       "1  “有什么问题我能帮你处理或解决呢？”中，“处理”和“解决”的主语都是“我”，宾语是“问题”，...  \n",
       "2  “我帮你问一下”，“帮”和“问”的主语都是我，但显然宾语不同，因此由第一个谓词“帮”发射“同...  \n",
       "3  “你把订单号发一下，我查询一下”，“发”和“查询”就是由不同主语所发出的动作，因此，由“发”...  \n",
       "4     “我买了洗衣液”，“我”是“买”这个动作的主体对象，因此由“买”发射一条“主语”弧到“我”。  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_df = pd.read_csv('../attribute.csv', sep=',')\n",
    "extra = pd.read_csv('../extra_attribute.csv', sep=',')\n",
    "\n",
    "attr_df = pd.concat([attr_df, extra], axis=0).reset_index()\n",
    "# attr_df = pd.concat([extra], axis=0).reset_index()\n",
    "attr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0db5e380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 168])\n"
     ]
    }
   ],
   "source": [
    "attrs = [\n",
    "    attr_df['rel_name'][i] + \n",
    "    '：' +\n",
    "    attr_df['attribute'][i] +\n",
    "    ' 例子：' + \n",
    "    attr_df['example'][i]\n",
    "    for i in range(len(attr_df))\n",
    "]\n",
    "\n",
    "\n",
    "# attrs[27:28] = [\n",
    "#     attrs[i] +\n",
    "#     attr_df['attribute'][2] +\n",
    "#     attr_df['attribute'][3]\n",
    "#     for i in range(27, 28)\n",
    "# ]\n",
    "\n",
    "# print(attrs)\n",
    "\n",
    "attr_tokenized = tokenizer(attrs, return_offsets_mapping=False, padding=True, return_tensors='pt')\n",
    "\n",
    "num_rels, attr_len = attr_tokenized['input_ids'].shape\n",
    "print(attr_tokenized['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "542a3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annoted(data_file):\n",
    "    with open(CFG.data_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    sample_lst:List[List[Dependency]] = []\n",
    "    \n",
    "    for d in data:\n",
    "        rel_dct = {}\n",
    "        for tripple in d['relationship']:\n",
    "            head, rel, tail = tripple\n",
    "            head_uttr_idx, head_word_idx = [int(x) for x in head.split('-')]\n",
    "            tail_uttr_idx, tail_word_idx = [int(x) for x in tail.split('-')]\n",
    "            if head_uttr_idx != tail_uttr_idx:\n",
    "                continue\n",
    "            \n",
    "            if not rel_dct.get(head_uttr_idx, None):\n",
    "                rel_dct[head_uttr_idx] = {tail_word_idx: [head_word_idx, rel]}\n",
    "            else:\n",
    "                rel_dct[head_uttr_idx][tail_word_idx] = [head_word_idx, rel]\n",
    "            \n",
    "        for item in d['dialog']:\n",
    "            turn = item['turn']\n",
    "            utterance = item['utterance']\n",
    "            # dep_lst:List[Dependency] = [Dependency(0, '[root]', -1, '_')]\n",
    "            dep_lst:List[Dependency] = []\n",
    "            \n",
    "            for word_idx, word in enumerate(utterance.split(' ')):\n",
    "                head_word_idx, rel = rel_dct[turn].get(word_idx + 1, [word_idx, 'adjct'])  # some word annoted missed, padded with last word and 'adjct'\n",
    "                dep_lst.append(Dependency(word_idx + 1, word, head_word_idx, rel))  # start from 1\n",
    "            \n",
    "            sample_lst.append(dep_lst)\n",
    "        \n",
    "    return sample_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d846a87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogDataset(Dataset):\n",
    "    def __init__(self, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.inputs, self.offsets, self.heads, self.rels, self.masks = self.read_data()\n",
    "        \n",
    "    def read_data(self):\n",
    "        inputs, offsets = [], []\n",
    "        tags, heads, rels, masks = [], [], [], []\n",
    "        \n",
    "        for deps in load_annoted(self.cfg.data_file):\n",
    "            seq_len = len(deps)\n",
    "\n",
    "            word_lst = [] \n",
    "            head_tokens = np.zeros(self.cfg.max_length, dtype=np.int64)  # same as root index is 0, constrainting by mask \n",
    "            rel_tokens = np.zeros(self.cfg.max_length, dtype=np.int64)\n",
    "            mask_tokens = np.zeros(self.cfg.max_length, dtype=np.int64)\n",
    "            for i, dep in enumerate(deps):\n",
    "                if i == seq_len or i + 1== self.cfg.max_length:\n",
    "                    break\n",
    "\n",
    "                word_lst.append(dep.word)\n",
    "\n",
    "                if dep.head == -1 or dep.head + 1 >= self.cfg.max_length:\n",
    "                # if dep.head == -1 or dep.head + 1 >= self.cfg.max_length:\n",
    "                    head_tokens[i+1] = 0\n",
    "                    mask_tokens[i+1] = 0\n",
    "                else:\n",
    "                    head_tokens[i+1] = int(dep.head)\n",
    "                    mask_tokens[i+1] = 1\n",
    "\n",
    "                rel_tokens[i+1] = rel2id.get(dep.rel, rel2id['adjct'])\n",
    "\n",
    "            tokenized = tokenizer.encode_plus(word_lst, \n",
    "                                              padding='max_length', \n",
    "                                              truncation=True,\n",
    "                                              max_length=self.cfg.max_length, \n",
    "                                              return_offsets_mapping=True, \n",
    "                                              return_tensors='pt',\n",
    "                                              is_split_into_words=True)\n",
    "            inputs.append({\"input_ids\": tokenized['input_ids'][0],\n",
    "                           \"token_type_ids\": tokenized['token_type_ids'][0],\n",
    "                           \"attention_mask\": tokenized['attention_mask'][0]\n",
    "                          })\n",
    "\n",
    "            sentence_word_idx = []\n",
    "            for idx, (start, end) in enumerate(tokenized.offset_mapping[0][1:]):\n",
    "                if start == 0 and end != 0:\n",
    "                    sentence_word_idx.append(idx)\n",
    "\n",
    "            if len(sentence_word_idx) < self.cfg.max_length - 1:\n",
    "                sentence_word_idx.extend([0]* (self.cfg.max_length - 1 - len(sentence_word_idx)))\n",
    "            offsets.append(torch.as_tensor(sentence_word_idx))\n",
    "\n",
    "            heads.append(head_tokens)\n",
    "            rels.append(rel_tokens)\n",
    "            masks.append(mask_tokens)\n",
    "                    \n",
    "        return inputs, offsets, heads, rels, masks\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.offsets[idx], self.heads[idx], self.rels[idx], self.masks[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25622676",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = DialogDataset(CFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4354ca7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a33d2a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-electra-180g-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# model = ParWithAttr(CFG, attr_tokenized)\n",
    "model = DepParser(CFG)\n",
    "# model.load_state_dict(torch.load('results/electra_bc_epoch15.pt'))\n",
    "print(model.load_state_dict(torch.load('../results/base_par_codt_3642.pt')))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4caa7f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "va_dataloader = DataLoader(val_dataset, batch_size=CFG.batch_size)\n",
    "\n",
    "arc_logits, rel_logits, similarities = torch.Tensor(), torch.Tensor(), torch.Tensor()\n",
    "heads_whole, rels_whole, masks_whole = torch.Tensor(), torch.Tensor(), torch.Tensor()\n",
    "for batch in va_dataloader:\n",
    "    inputs, offsets, heads, rels, masks = batch\n",
    "\n",
    "    inputs_cuda = {}\n",
    "    for key, value in inputs.items():\n",
    "        inputs_cuda[key] = value.cuda()\n",
    "    inputs = inputs_cuda\n",
    "\n",
    "    offsets, heads, rels, masks = to_cuda(data=(offsets, heads, rels, masks))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # arc_logit, rel_logit, similarity = model.predict(inputs, offsets, masks)\n",
    "        arc_logit, rel_logit = model(inputs, offsets, heads, rels, masks, evaluate=True)\n",
    "        \n",
    "    arc_logit[:, torch.arange(arc_logit.size()[1]), torch.arange(arc_logit.size()[2])] = -1e4\n",
    "    \n",
    "    arc_logits = torch.cat([arc_logits, arc_logit.cpu()])\n",
    "    rel_logits = torch.cat([rel_logits, rel_logit.cpu()])\n",
    "    # similarities = torch.cat([similarities, similarity.cpu()])\n",
    "    \n",
    "    heads_whole = torch.cat([heads_whole, heads.cpu()])\n",
    "    rels_whole = torch.cat([rels_whole, rels.cpu()])\n",
    "    masks_whole = torch.cat([masks_whole, masks.cpu()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7cdbf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-electra-180g-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "CFG.num_labels = 21\n",
    "model = DepParser(CFG)\n",
    "# model.load_state_dict(torch.load('results/electra_bc_epoch15.pt'))\n",
    "print(model.load_state_dict(torch.load('../results/base_par.pt')))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5f42849",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "va_dataloader = DataLoader(val_dataset, batch_size=CFG.batch_size)\n",
    "\n",
    "arc_logits_another, rel_logits_another = torch.Tensor(), torch.Tensor()\n",
    "for batch in va_dataloader:\n",
    "    inputs, offsets, heads, rels, masks = batch\n",
    "\n",
    "    inputs_cuda = {}\n",
    "    for key, value in inputs.items():\n",
    "        inputs_cuda[key] = value.cuda()\n",
    "    inputs = inputs_cuda\n",
    "\n",
    "    offsets, heads, rels, masks = to_cuda(data=(offsets, heads, rels, masks))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # arc_logit, rel_logit, similarity = model.predict(inputs, offsets, masks)\n",
    "        arc_logit, rel_logit = model(inputs, offsets, heads, rels, masks, evaluate=True)\n",
    "        \n",
    "    arc_logit[:, torch.arange(arc_logit.size()[1]), torch.arange(arc_logit.size()[2])] = -1e4\n",
    "    \n",
    "    arc_logits_another = torch.cat([arc_logits_another, arc_logit.cpu()])\n",
    "    rel_logits_another = torch.cat([rel_logits_another, rel_logit.cpu()])\n",
    "    # similarities = torch.cat([similarities, similarity.cpu()])\n",
    "    \n",
    "    # heads_whole = torch.cat([heads_whole, heads.cpu()])\n",
    "    # rels_whole = torch.cat([rels_whole, rels.cpu()])\n",
    "    # masks_whole = torch.cat([masks_whole, masks.cpu()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e05e4b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcdc21e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20086, 160, 21])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_logits_another.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6df89747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arc_logits /=2\n",
    "# arc_logits += arc_logits_another/2\n",
    "\n",
    "# rel_logits /=2\n",
    "# rel_logits[:, :, :21]  += rel_logits_another/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e4eb0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UAS': 0.8501551560687515, 'LAS': 0.788198717533519}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uas_las(arc_logits=arc_logits_another,\n",
    "        rel_logits=rel_logits_another,\n",
    "        arc_gt=heads_whole,\n",
    "        rel_gt=rels_whole,\n",
    "        mask=masks_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c37bccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_logits_tmp = arc_logits.clone()\n",
    "rel_logits_tmp = rel_logits.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf103ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_logits = arc_logits_tmp.clone()\n",
    "rel_logits = rel_logits_tmp.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "144f6974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_logits= rel_logits.softmax(-1)\n",
    "# rel_logits_another = torch.cat([rel_logits_another, torch.full((rel_logits_another.size(0), CFG.max_length, 14), fill_value=-1e3)], dim=-1).softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2786413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_logits= rel_logits\n",
    "# rel_logits_another = torch.cat([rel_logits_another, torch.full((rel_logits_another.size(0), CFG.max_length, 14), fill_value=-1e3)], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d826bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_logits = arc_logits.softmax(-1)\n",
    "arc_logits_another = arc_logits_another.softmax(-1)\n",
    "\n",
    "rel_logits = rel_logits.softmax(-1)\n",
    "rel_logits_another = rel_logits_another.softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d04c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arc_logits *= 0.8\n",
    "# arc_logits += 0.2 * arc_logits_another\n",
    "# rel_logits[:, :, :21] *= 0.8\n",
    "# rel_logits[:, :, :21] += 0.2 * rel_logits_another[:, :, :21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "511556e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arc_logits *= 0.4\n",
    "# arc_logits += torch.where((rel_logits_another.argmax(-1) < 21).unsqueeze(-1).expand(-1, -1, arc_logits.size(-1)), 0.6 * arc_logits_another, 0.6 * arc_logits)\n",
    "\n",
    "# rel_logits[:, :, :21] *= 0.4\n",
    "# rel_logits[:, :, :21] += torch.where((rel_logits_another.argmax(-1) < 21).unsqueeze(-1).expand(-1, -1, rel_logits_another.size(-1)), 0.6 * rel_logits_another, 0.6 * rel_logits[:, :, :21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e01fc1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arc_logits *= 0.7\n",
    "# arc_logits += torch.where(arc_logits > arc_logits_another, 0.3 * arc_logits, 0.3 * arc_logits_another)\n",
    "\n",
    "# rel_logits[:, :, :21] *= 0.7\n",
    "# rel_logits[:, :, :21] += torch.where(rel_logits[:, :, :21] > rel_logits_another, 0.3 * rel_logits[:, :, :21], 0.3 * rel_logits_another)\n",
    "\n",
    "\n",
    "arc_logits = torch.where(arc_logits > arc_logits_another, arc_logits, arc_logits_another)\n",
    "rel_logits[:, :, :21] = torch.where(rel_logits[:, :, :21] > rel_logits_another, rel_logits[:, :, :21], rel_logits_another)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67661f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UAS': 0.8505791119302357, 'LAS': 0.7979320375200938}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uas_las(arc_logits=arc_logits,\n",
    "        rel_logits=rel_logits,\n",
    "        arc_gt=heads_whole,\n",
    "        rel_gt=rels_whole,\n",
    "        mask=masks_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1c12efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uas_las(arc_logits=arc_logits,\n",
    "#         rel_logits=similarities,\n",
    "#         arc_gt=heads_whole,\n",
    "#         rel_gt=rels_whole,\n",
    "#         mask=masks_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45ffe34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_preds = similarities.argmax(-1)\n",
    "# # rel_preds.masked_fill_(rel_preds == 2, 27)\n",
    "# # rel_preds.masked_fill_(rel_preds == 3, 27)\n",
    "\n",
    "# arc_logits_correct = (arc_logits.argmax(-1) == heads_whole).long() * masks_whole * (rels_whole >= 21).long()\n",
    "# rel_logits_correct = (rel_preds == rels_whole).long() * arc_logits_correct\n",
    "\n",
    "# print(rel_logits_correct.sum() / (rels_whole >= 21).long().sum())\n",
    "# print(arc_logits_correct.sum() / (rels_whole >= 21).long().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23403b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1702)\n",
      "tensor(0.5043)\n",
      "---------------------------------------------------\n",
      "tensor(0.8373)\n",
      "tensor(0.8723)\n",
      "===================================================\n",
      "tensor(0.3417)\n",
      "tensor(0.5043)\n",
      "---------------------------------------------------\n",
      "tensor(0.8273)\n",
      "tensor(0.8723)\n"
     ]
    }
   ],
   "source": [
    "rel_preds = rel_logits.argmax(-1)\n",
    "head_pred = arc_logits.argmax(-1)\n",
    "\n",
    "arc_logits_correct = (head_pred == heads_whole).long() * masks_whole * (rels_whole >= 21).long()\n",
    "rel_logits_correct = (rel_preds == rels_whole).long() * arc_logits_correct\n",
    "\n",
    "print(rel_logits_correct.sum() / (rels_whole >= 21).long().sum())\n",
    "print(arc_logits_correct.sum() / (rels_whole >= 21).long().sum())\n",
    "print('---------------------------------------------------')\n",
    "arc_logits_correct = (head_pred == heads_whole).long() * masks_whole * (rels_whole < 21).long()\n",
    "rel_logits_correct = (rel_preds == rels_whole).long() * arc_logits_correct \n",
    "\n",
    "print(rel_logits_correct.sum() / (masks_whole * (rels_whole < 21).long()).sum())\n",
    "print(arc_logits_correct.sum() / (masks_whole * (rels_whole < 21).long()).sum())\n",
    "\n",
    "print('===================================================')\n",
    "\n",
    "rel_preds.masked_fill_(rel_preds == 2, 27)\n",
    "rel_preds.masked_fill_(rel_preds == 3, 27)\n",
    "# rel_preds.masked_fill_(rel_preds == 6, 27)\n",
    "# rel_preds.masked_fill_(rel_preds == 12, 27)\n",
    "# rel_preds.masked_fill_(rel_preds != 27, 27)\n",
    "\n",
    "arc_logits_correct = (head_pred == heads_whole).long() * masks_whole * (rels_whole >= 21).long()\n",
    "rel_logits_correct = (rel_preds == rels_whole).long() * arc_logits_correct\n",
    "\n",
    "print(rel_logits_correct.sum() / (rels_whole >= 21).long().sum())\n",
    "print(arc_logits_correct.sum() / (rels_whole >= 21).long().sum())\n",
    "print('---------------------------------------------------')\n",
    "\n",
    "arc_logits_correct = (head_pred == heads_whole).long() * masks_whole * (rels_whole < 21).long()\n",
    "rel_logits_correct = (rel_preds == rels_whole).long() * arc_logits_correct \n",
    "\n",
    "print(rel_logits_correct.sum() / (masks_whole * (rels_whole < 21).long()).sum())\n",
    "print(arc_logits_correct.sum() / (masks_whole * (rels_whole < 21).long()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0659b45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.0314)\n",
      "tensor(0.0067)\n",
      "tensor(0.0095)\n",
      "tensor(0.1069)\n",
      "tensor(0.2627)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.0344)\n",
      "tensor(0.)\n",
      "tensor(0.0047)\n",
      "tensor(0.0156)\n"
     ]
    }
   ],
   "source": [
    "rel_preds = rel_logits.argmax(-1)\n",
    "head_preds = arc_logits.argmax(-1)\n",
    "\n",
    "# rel_preds.masked_fill_(rel_preds == 2, 27)\n",
    "# rel_preds.masked_fill_(rel_preds == 3, 27)\n",
    "\n",
    "for i in range(21, 35):\n",
    "    arc_logits_correct = (head_pred == heads_whole).long() * masks_whole * (rels_whole == i).long()\n",
    "    rel_logits_correct = (rel_preds == rels_whole).long() * arc_logits_correct\n",
    "\n",
    "    print(rel_logits_correct.sum() / (rels_whole == i).long().sum())\n",
    "    # print(arc_logits_correct.sum() / (rels_whole == i).long().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5b42dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'说': 21, '表示': 21, '看': 21, '显示': 21, '知道': 21, '认为': 21, '希望': 21, '指出': 21, '如果': 25, '假如': 25, '的话': 25, '若': 25, '如': 25, '因为': 23, '所以': 23, '导致': 23, '因此': 23, '造成': 23, '由于': 23, '因而': 23, '但是': 26, '可是': 26, '但': 26, '竟': 26, '却': 26, '不过': 26, '居然': 26, '而是': 26, '以及': 31, '也': 31, '并': 31, '并且': 31, '又': 31, '或者': 31, '对于': 22, '自从': 22, '之前': 22, '上次': 22, '明天': 34, '晚上': 34, '到时候': 34, '再': 34, '然后': 34, '接下来': 34, '最后': 34, '随后': 34, '为了': 28, '想要': 28, '使': 28, '为 的': 28, '通过': 32, '必须': 32, '点击': 32, '对 吗': 33, '是 吗': 33, '对 吧': 33, '是 吧': 33, '对 ?': 33, '更': 24, '比': 24, '只': 24, '解释': 30, '比如': 30, '例如': 30, '是 这样': 30, '理想': 29, '真 棒': 29, '太 棒': 29, '真差': 29, '太 差': 29, '不 行': 29, '扯皮': 29}\n"
     ]
    }
   ],
   "source": [
    "from constant import rel2id, punct_lst, weak_signals, weak_labels\n",
    "\n",
    "priority = {\n",
    "    rel2id['cont']: 1,\n",
    "    rel2id['temp']: 2, rel2id['cause']: 2, rel2id['bckg']: 2, rel2id['comp']: 2,\n",
    "    rel2id['joint']: 3, rel2id['attr']: 3,\n",
    "    None: 5,  # 4 is default\n",
    "}\n",
    "\n",
    "reverse_by_words = [\n",
    "    '你 好', '您 好',\n",
    "]\n",
    "\n",
    "id2rel = list(rel2id.keys())\n",
    "\n",
    "origin4change = [rel2id[x] for x in ['root', 'dfsubj', 'sasubj']]\n",
    "\n",
    "signal_dct = {}\n",
    "for i, signals in enumerate(weak_signals):\n",
    "    for s in signals:\n",
    "        signal_dct[s] = weak_labels[i]\n",
    "print(signal_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f7be283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20086it [00:45, 436.89it/s]\n"
     ]
    }
   ],
   "source": [
    "rel_preds = rel_logits.argmax(-1)\n",
    "head_preds = arc_logits.argmax(-1)\n",
    "\n",
    "max_len = CFG.max_length\n",
    "\n",
    "signals_new_whole = torch.Tensor()\n",
    "heads_new_whole, rels_new_whole = torch.Tensor(), torch.Tensor()\n",
    "for sample_idx, deps in tqdm(enumerate(load_annoted(CFG.data_file))):\n",
    "    seq_len = len(deps)\n",
    "    if seq_len == 0:\n",
    "        continue\n",
    "    \n",
    "    signals = torch.zeros(max_len).int()\n",
    "    heads, rels = torch.full(size=(max_len,), fill_value=-2).int(), torch.zeros(max_len).int()\n",
    "    split, splits, signal, word_lst  = 1, [], None, ['root']\n",
    "    for i, dep in enumerate(deps[:-1]):\n",
    "        if i + 2 >= max_len:\n",
    "            break\n",
    "        \n",
    "        word = dep.word\n",
    "        word_lst.append(word)\n",
    "        if word in signal_dct.keys() and priority.get(signal_dct[word], 4) < priority.get(signal, 4):\n",
    "            signal = signal_dct[word]\n",
    "        if f'{word} {deps[i+1].word}' in signal_dct.keys() and priority.get(signal_dct[f'{word} {deps[i+1].word}'], 4) < priority.get(signal, 4):\n",
    "            signal = signal_dct[f'{word} {deps[i+1].word}']\n",
    "        \n",
    "        if word in punct_lst and deps[i+1].word not in punct_lst:\n",
    "            if signal is not None and i + 2 - split > 2:  # set 2 to the min length of edu\n",
    "                signals[split:i+2] = signal\n",
    "                signal = None\n",
    "            splits.append(split)\n",
    "            split = i + 2\n",
    "\n",
    "        # if masks_whole[sample_idx, i+1] == 0:\n",
    "        #     heads[i+1] = -1\n",
    "        #     rels[i+1] = -1\n",
    "        # else:\n",
    "        #     heads[i+1] = head_preds[sample_idx, i+1]\n",
    "        #     rels[i+1] = rel_preds[sample_idx, i+1]\n",
    "\n",
    "    # add the last data\n",
    "    if i + 1 < max_len:\n",
    "        word_lst.append(word)\n",
    "\n",
    "        # if masks_whole[sample_idx, i+1] == 0:\n",
    "        #     heads[i+1] = -1\n",
    "        #     rels[i+1] = -1\n",
    "        # else:\n",
    "        #     heads[i+1] = head_preds[sample_idx, i+1]\n",
    "        #     rels[i+1] = rel_preds[sample_idx, i+1]\n",
    "\n",
    "    heads = head_preds[sample_idx]\n",
    "    heads.masked_fill_(mask=~masks_whole[sample_idx].bool(), value=-2)\n",
    "\n",
    "    rels = rel_preds[sample_idx]\n",
    "    rels.masked_fill_(mask=~masks_whole[sample_idx].bool(), value=-2)\n",
    "\n",
    "    if split > 1:\n",
    "        splits.append(split)\n",
    "        if signal is not None:\n",
    "            signals[split:i+2] = signal\n",
    "    \n",
    "    splits.append(len(deps))\n",
    "    # when num of 'edu' >= 2, try change rel and head\n",
    "    # if len(splits) > 2:\n",
    "    cnt = -1\n",
    "    for idx, head in enumerate(heads[1:]):\n",
    "        if head == -2:\n",
    "            break\n",
    "        if head == -1:\n",
    "            continue\n",
    "\n",
    "        if len(splits) > 2 and idx + 1 >= splits[cnt+1]:\n",
    "            cnt += 1\n",
    "\n",
    "        if ((len(splits) > 2 and (head < splits[cnt] or head >= splits[cnt+1])) or idx - head > 0) and rels[idx + 1] in origin4change:  # cross 'edu'\n",
    "            if signals[idx+1] != 0:\n",
    "                rels[idx+1] = signals[idx+1]\n",
    "                \n",
    "                if head == 0 and rels[idx + 1] in [rel2id['cond']]:  # reverse\n",
    "                    tmp_heads = heads.clone()\n",
    "                    tmp_heads[:splits[cnt+1]] = 0\n",
    "                    head_idx = [idx + 1]\n",
    "                    tail_idx = (tmp_heads == idx + 1).nonzero()  # find tail index\n",
    "                    if len(tail_idx) == 0:  # ring or fail\n",
    "                        # if 'cont', revsere root; else unchange\n",
    "                        tail_idx = (heads == idx + 1).nonzero() if signals[idx+1] == rel2id['cont'] else [idx + 1]\n",
    "                        head_idx = (heads == idx + 1).nonzero() if head_idx == tail_idx else head_idx\n",
    "                    if len(head_idx) != 0:\n",
    "                        heads[tail_idx[0]] = 0\n",
    "                        heads[head_idx[0]] = tail_idx[0]\n",
    "            elif head != 0:  # default\n",
    "                rels[idx + 1] = rel2id['elbr']\n",
    "\n",
    "            # special cases\n",
    "            if len(splits) > 2 and word_lst[idx+1] == '好' and word_lst[idx] in ['你', '您']:  # reverse\n",
    "                tmp_heads = heads.clone()\n",
    "                tmp_heads[:splits[cnt+1]] = 0\n",
    "                tail_idx = (tmp_heads == idx + 1).nonzero()  # find tail index\n",
    "                if len(tail_idx) != 0:  \n",
    "                    heads[tail_idx[0]] = 0\n",
    "                    heads[idx + 1] = tail_idx[0]\n",
    "                    rels[idx + 1] = rel2id['elbr']\n",
    "\n",
    "            # 'attr' label should be reversed again; below can match most of cases\n",
    "            if splits[cnt] == 1 and rels[idx + 1] in [rel2id['attr']]:\n",
    "                tmp_heads = heads.clone()\n",
    "                tmp_heads[:splits[cnt+1]] = 0\n",
    "                tail_idx = ((tmp_heads != 0) * (tmp_heads >= splits[cnt]) * (tmp_heads < splits[cnt + 1])).nonzero().flatten()\n",
    "                if len(tail_idx) != 0 and rels[tail_idx[0]] in origin4change:\n",
    "                    heads[tail_idx[0]] = idx + 1\n",
    "                    rels[tail_idx[0]] = rels[idx + 1]\n",
    "                else:\n",
    "                    dep_idx = heads[idx + 1].item()\n",
    "                    if dep_idx != 0 and (dep_idx < splits[cnt] or dep_idx > splits[cnt+1]):\n",
    "                        heads[idx + 1] = 0\n",
    "                        heads[dep_idx] = idx + 1\n",
    "                        rels[dep_idx] = rels[idx + 1]\n",
    "\n",
    "    rels.masked_fill_(heads == 0, 0)  # root\n",
    "    heads[0] = 0\n",
    "    heads[1:].masked_fill_(heads[1:] == -2, 0)\n",
    "\n",
    "    heads_new_whole = torch.cat([heads_new_whole, heads.unsqueeze(0)])\n",
    "    rels_new_whole = torch.cat([rels_new_whole, rels.unsqueeze(0)])\n",
    "    signals_new_whole = torch.cat([signals_new_whole, signals.unsqueeze(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6393e96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3489)\n",
      "tensor(0.5243)\n",
      "---------------------------------------------------\n",
      "tensor(0.8312)\n",
      "tensor(0.8735)\n"
     ]
    }
   ],
   "source": [
    "arc_logits_correct = (heads_new_whole == heads_whole).long() * masks_whole * (rels_whole >= 21).long()\n",
    "rel_logits_correct = (rels_new_whole == rels_whole).long() * arc_logits_correct\n",
    "\n",
    "print(rel_logits_correct.sum() / (rels_whole >= 21).long().sum())\n",
    "print(arc_logits_correct.sum() / (rels_whole >= 21).long().sum())\n",
    "print('---------------------------------------------------')\n",
    "\n",
    "arc_logits_correct = (heads_new_whole == heads_whole).long() * masks_whole * (rels_whole < 21).long()\n",
    "rel_logits_correct = (rels_new_whole == rels_whole).long() * arc_logits_correct \n",
    "\n",
    "print(rel_logits_correct.sum() / (masks_whole * (rels_whole < 21).long()).sum())\n",
    "print(arc_logits_correct.sum() / (masks_whole * (rels_whole < 21).long()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3bf615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(heads_new_whole, '../preds/head_preds.pt')\n",
    "torch.save(rels_new_whole, '../preds/rel_preds.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "111ec777",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "argmax(): Expected reduction dim -1 to have non-zero size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13610/1282323337.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrel_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnew_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: argmax(): Expected reduction dim -1 to have non-zero size."
     ]
    }
   ],
   "source": [
    "rel_preds = similarities.argmax(-1)\n",
    "values, topk = similarities.topk(k=2, dim=-1)\n",
    "\n",
    "new_preds = []\n",
    "for pred, value in tqdm(zip(topk, values)):\n",
    "    tmp = []\n",
    "    for p, v in zip(pred, value):\n",
    "        if p[0] < 21:\n",
    "            if p[1] >= 21:\n",
    "                tmp.append(p[1])\n",
    "                continue\n",
    "            # if p[2] >= 21:\n",
    "            #     tmp.append(p[2])\n",
    "            #     continue\n",
    "        tmp.append(p[0])\n",
    "    new_preds.append(tmp)\n",
    "\n",
    "new_preds = torch.tensor(new_preds)\n",
    "arc_logits_correct = (arc_logits.argmax(-1) == heads_whole).long() * (rels_whole >= 21).long()\n",
    "rel_logits_correct = (new_preds == rels_whole).long() * arc_logits_correct \n",
    "\n",
    "print(rel_logits_correct.sum() / (rels_whole >= 21).long().sum())\n",
    "print(arc_logits_correct.sum() / (rels_whole >= 21).long().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7138e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_preds = rel_logits.argmax(-1)\n",
    "rel_preds.masked_fill_(rel_preds == 2, 27)\n",
    "rel_preds.masked_fill_(rel_preds == 3, 27)\n",
    "\n",
    "arc_logits_correct = (arc_logits.argmax(-1) == heads_whole).long() * masks_whole * (rels_whole >= 21).long()\n",
    "rel_logits_correct = (rel_preds == rels_whole).long() * arc_logits_correct\n",
    "\n",
    "print(rel_logits_correct.sum() / (rels_whole >= 21).long().sum())\n",
    "print(arc_logits_correct.sum() / (rels_whole >= 21).long().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5e8b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_preds = rel_logits.argmax(-1)\n",
    "\n",
    "arc_logits_correct = (arc_logits.argmax(-1) == heads_whole).long() * masks_whole * (rels_whole >= 21).long()\n",
    "rel_logits_correct = (rel_preds == rels_whole).long() * arc_logits_correct\n",
    "\n",
    "print(rel_logits_correct.sum() / ((rels_whole == 2).long() + (rels_whole == 3).long()).sum())\n",
    "print(arc_logits_correct.sum() / ((rels_whole == 2).long() + (rels_whole == 3).long()).sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('jgy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f5970cc3159b15dedb1f3a2bddfb758e67a1721376b7397fa1f3df8941c2f173"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
