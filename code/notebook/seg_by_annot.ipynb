{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b94ee4e6-b849-4c36-a792-d70966995f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from typing import *\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b18178-3e0f-48b5-b678-6d2978454b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, AdamW, get_constant_schedule_with_warmup, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "476905cc-48f4-4fd9-a1b9-0a743bc39105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils import to_cuda, arc_rel_loss, uas_las\n",
    "from constant import punct_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6ba16-bdc2-40e9-8553-80654adf823b",
   "metadata": {},
   "source": [
    "## Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "658e532b-ef45-44af-8092-b5640a581603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    np.random.seed(seed%(2**32-1))\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic =True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9133215f-de2a-43fc-92b2-c40d07924f0e",
   "metadata": {},
   "source": [
    "## CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a5780b0-a2f5-4ce9-8ebb-d404e31c7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    data_file = 'data/seg_with_train.json'\n",
    "    plm = 'hfl/chinese-electra-180g-large-discriminator'\n",
    "    num_folds = 5\n",
    "    trn_folds = [0]  # only one fold, as splitting train/val randomly\n",
    "    random_seed = 42\n",
    "    num_epochs = 3\n",
    "    batch_size = 128\n",
    "    max_length = 160\n",
    "    num_labels = 2\n",
    "    lr = 2e-5\n",
    "    weight_decay = 0.01\n",
    "    dropout = 0.2\n",
    "    grad_clip = 1\n",
    "    scheduler = 'linear'\n",
    "    warmup_ratio = 0.1\n",
    "    num_early_stop = 5\n",
    "    hidden_size = 400\n",
    "    print_every = 500  \n",
    "    eval_every = 1000\n",
    "    cuda = True\n",
    "    fp16 = True\n",
    "    debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1bdbce9-baed-44bf-a9d1-cf75c25e4d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../data_testset/1to800_1108.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dab531e2-7901-46c2-80e7-b4b2c97ef500",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_file, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f667f5ac-a11a-475c-a14b-87c8eaa1ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dependency():\n",
    "    def __init__(self, idx, word, head, rel):\n",
    "        self.id = idx\n",
    "        self.word = word\n",
    "        self.tag = '_'\n",
    "        self.head = head\n",
    "        self.rel = rel\n",
    "\n",
    "    def __str__(self):\n",
    "        # example:  1\t上海\t_\tNR\tNR\t_\t2\tnn\t_\t_\n",
    "        values = [str(self.idx), self.word, \"_\", self.tag, \"_\", \"_\", str(self.head), self.rel, \"_\", \"_\"]\n",
    "        return '\\t'.join(values)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"({self.word}, {self.tag}, {self.head}, {self.rel})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bce0e85b-3ff1-4069-b67d-71328fc64fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['attr', 'bckg', 'cause', 'comp', 'cond', 'cont', 'elbr', 'enbm', 'eval', 'expl', 'joint', 'manner', 'rstm', 'temp', 'tp-chg', 'prob-sol', 'qst-ans', 'stm-rsp', 'req-proc']\n"
     ]
    }
   ],
   "source": [
    "rst_dct = {\n",
    "    'attr': '归属',\n",
    "    'bckg': '背景',\n",
    "    'cause': '因果',\n",
    "    'comp': '比较',\n",
    "    'cond': '状况',\n",
    "    'cont': '对比',\n",
    "    'elbr': '阐述',\n",
    "    'enbm': '目的',\n",
    "    'eval': '评价',\n",
    "    'expl': '解释-例证',\n",
    "    'joint': '联合',\n",
    "    'manner': '方式',\n",
    "    'rstm': '重申',\n",
    "    'temp': '时序',\n",
    "    'tp-chg': '主题变更',\n",
    "    'prob-sol': '问题-解决',\n",
    "    'qst-ans': '疑问-回答',\n",
    "    'stm-rsp': '陈述-回应',\n",
    "    'req-proc': '需求-处理',\n",
    "}\n",
    "\n",
    "rst_lst = [x for x in rst_dct.keys()]\n",
    "print(rst_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3d0f9a9-1719-4eb8-bf55-b942b40165e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "\n",
    "sample_lst:List[List[Dependency]] = []\n",
    "split_ids_lst = []\n",
    "a, b = 278, 1\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "    # if i != a - 1:\n",
    "    #     continue\n",
    "        \n",
    "    rel_dct = {}\n",
    "    for tripple in d['relationship']:\n",
    "        head, rel, tail = tripple\n",
    "        head_uttr_idx, head_word_idx = [int(x) for x in head.split('-')]\n",
    "        tail_uttr_idx, tail_word_idx = [int(x) for x in tail.split('-')]\n",
    "        if head_uttr_idx != tail_uttr_idx:\n",
    "            continue\n",
    "\n",
    "        if not rel_dct.get(head_uttr_idx, None):\n",
    "            rel_dct[head_uttr_idx] = {tail_word_idx: [head_word_idx, rel]}\n",
    "        else:\n",
    "            rel_dct[head_uttr_idx][tail_word_idx] = [head_word_idx, rel]\n",
    "    \n",
    "    \n",
    "    for item in d['dialog']:\n",
    "        turn = item['turn']\n",
    "        # if turn != b - 1:\n",
    "        #     continue\n",
    "        utterance = item['utterance']\n",
    "        # print(utterance)\n",
    "        dep_lst:List[Dependency] = []\n",
    "        \n",
    "        edus = [[-1, -1]]  # 0 for root\n",
    "        inner_rels, inter_rels = [], []\n",
    "        for word_idx, word in enumerate(utterance.split(' ')):\n",
    "            head_word_idx, rel = rel_dct[turn].get(word_idx + 1, [word_idx, 'adjct'])  # some word annoted missed, padded with last word and 'adjct'\n",
    "            \n",
    "            if rel in rst_lst:\n",
    "                inter_rels.append(rel)\n",
    "                edus.append([word_idx + 1, word_idx + 1])\n",
    "                continue\n",
    "            \n",
    "            expand, include = False, False\n",
    "            for edu in edus:\n",
    "                if edu[0] <= head_word_idx <= edu[1]:\n",
    "                    edu[0] = min(edu[0], word_idx + 1)\n",
    "                    edu[1] = max(edu[1], word_idx + 1)\n",
    "                    expand = True\n",
    "                    break\n",
    "                elif edu[0] <= word_idx + 1 <= edu[1] and head_word_idx != 0:\n",
    "                    edu[0] = min(edu[0], head_word_idx)\n",
    "                    edu[1] = max(edu[1], head_word_idx)\n",
    "                    include = True\n",
    "                    break\n",
    "                    \n",
    "            if not expand and not include:\n",
    "                if head_word_idx == 0:  # ignore root\n",
    "                    edus.append([word_idx + 1, word_idx + 1])\n",
    "                else:\n",
    "                    # max with 1 to ignore root index\n",
    "                    edus.append([max(min(word_idx + 1, head_word_idx), 1), max(word_idx + 1, head_word_idx)])\n",
    "            inner_rels.append(rel)\n",
    "            \n",
    "            dep_lst.append(Dependency(word_idx + 1, word, head_word_idx, rel))  # start from 1\n",
    "        \n",
    "        # print(edus)\n",
    "        \n",
    "        finals = [edus[1]]\n",
    "        if len(edus) >= 2:\n",
    "            for edu in edus[2:]:\n",
    "                if finals[-1][0] <= edu[0] <= edu[1] <= finals[-1][1]:\n",
    "                    continue\n",
    "                finals.append(edu)\n",
    "                \n",
    "        split_ids = [x[1] for x in finals]\n",
    "        split_ids_lst.append(split_ids)\n",
    "#         print(split_ids)      \n",
    "        \n",
    "#         print(finals)\n",
    "#         print(dep_lst)\n",
    "        \n",
    "        sample_lst.append(dep_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed6a87c7-1054-4527-86b5-f9d4fd4d0930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(有, _, 0, root),\n",
       " (什么, _, 3, att),\n",
       " (问题, _, 1, obj),\n",
       " (我, _, 6, subj),\n",
       " (可以, _, 6, adv),\n",
       " (您, _, 6, obj),\n",
       " (处理, _, 6, sasubj),\n",
       " (或, _, 10, adjct),\n",
       " (解决, _, 8, sasubj-obj),\n",
       " (呢, _, 6, adjct),\n",
       " (?, _, 11, punc)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f961376-d3c6-465f-b3e8-74dd57366e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 12]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ids_lst[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f992e2e-412b-4018-8386-4c240f9133ec",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bebd5c86-2e0a-4bae-b5b1-e8f323355559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21128\n",
      "add token: [root] 21128\n",
      "add token: [qst] 21129\n",
      "add token: [ans] 21130\n",
      "21131\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG.plm)\n",
    "print(len(tokenizer))\n",
    " \n",
    "num_added_toks = tokenizer.add_tokens(['[root]', '[qst]', '[ans]'], special_tokens=True)\n",
    "tokenizer.root_token = '[root]'\n",
    "tokenizer.root_token_ids = tokenizer('[root]')['input_ids'][1]\n",
    "print(f\"add token: {tokenizer.root_token} {tokenizer.root_token_ids}\")\n",
    "\n",
    "tokenizer.qst_token = '[qst]'\n",
    "tokenizer.qst_token_ids = tokenizer('[qst]')['input_ids'][1]\n",
    "print(f\"add token: {tokenizer.qst_token} {tokenizer.qst_token_ids}\")\n",
    "\n",
    "tokenizer.ans_token = '[ans]'\n",
    "tokenizer.ans_token_ids = tokenizer('[ans]')['input_ids'][1]\n",
    "print(f\"add token: {tokenizer.ans_token} {tokenizer.ans_token_ids}\")\n",
    "print(len(tokenizer))\n",
    "\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faaf14a6-2719-4417-b9ef-71a3034353c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(data):\n",
    "    special_tokens = {\n",
    "        \"Q\": \"[qst]\",\n",
    "        \"A\": \"[ans]\",\n",
    "    }    \n",
    "\n",
    "    for i, d in enumerate(data):\n",
    "        rel_dct = {}\n",
    "        for tripple in d['relationship']:\n",
    "            head, rel, tail = tripple\n",
    "            head_uttr_idx, head_word_idx = [int(x) for x in head.split('-')]\n",
    "            tail_uttr_idx, tail_word_idx = [int(x) for x in tail.split('-')]\n",
    "            if head_uttr_idx != tail_uttr_idx:\n",
    "                continue\n",
    "\n",
    "            if not rel_dct.get(head_uttr_idx, None):\n",
    "                rel_dct[head_uttr_idx] = {tail_word_idx: [head_word_idx, rel]}\n",
    "            else:\n",
    "                rel_dct[head_uttr_idx][tail_word_idx] = [head_word_idx, rel]\n",
    "\n",
    "\n",
    "        for item in d['dialog']:\n",
    "            turn = item['turn']\n",
    "            speaker = item['speaker']\n",
    "            utterance = item['utterance']\n",
    "            dep_lst:List[Dependency] = []\n",
    "\n",
    "            edus = [[-1, -1]]  # 0 for root\n",
    "            inner_rels, inter_rels = [], []\n",
    "            for word_idx, word in enumerate(utterance.split(' ')):\n",
    "                head_word_idx, rel = rel_dct[turn].get(word_idx + 1, [word_idx, 'adjct'])  # some word annoted missed, padded with last word and 'adjct'\n",
    "\n",
    "                if rel in rst_lst:\n",
    "                    inter_rels.append(rel)\n",
    "                    edus.append([word_idx + 1, word_idx + 1])\n",
    "                    continue\n",
    "\n",
    "                expand, include = False, False\n",
    "                for edu in edus:\n",
    "                    if edu[0] <= head_word_idx <= edu[1]:\n",
    "                        edu[0] = min(edu[0], word_idx + 1)\n",
    "                        edu[1] = max(edu[1], word_idx + 1)\n",
    "                        expand = True\n",
    "                        break\n",
    "                    elif edu[0] <= word_idx + 1 <= edu[1] and head_word_idx != 0:\n",
    "                        edu[0] = min(edu[0], head_word_idx)\n",
    "                        edu[1] = max(edu[1], head_word_idx)\n",
    "                        include = True\n",
    "                        break\n",
    "\n",
    "                if not expand and not include:\n",
    "                    if head_word_idx == 0:  # ignore root\n",
    "                        edus.append([word_idx + 1, word_idx + 1])\n",
    "                    else:\n",
    "                        # max with 1 to ignore root index\n",
    "                        edus.append([max(min(word_idx + 1, head_word_idx), 1), max(word_idx + 1, head_word_idx)])\n",
    "                inner_rels.append(rel)\n",
    "\n",
    "                dep_lst.append(Dependency(word_idx + 1, word, head_word_idx, rel))  # start from 1\n",
    "\n",
    "            finals = [edus[1]]\n",
    "            if len(edus) >= 2:\n",
    "                for edu in edus[2:]:\n",
    "                    if finals[-1][0] <= edu[0] <= edu[1] <= finals[-1][1]:\n",
    "                        continue\n",
    "                    finals.append(edu)\n",
    "\n",
    "            split_ids = [x[1] for x in finals]\n",
    "\n",
    "            yield [special_tokens[speaker]] + utterance.split(' '), split_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad89d89f-8280-43b7-a0e8-d2606ea94c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EduDataset(Dataset):\n",
    "    def __init__(self, cfg, data):\n",
    "        self.cfg = cfg\n",
    "        self.data = data\n",
    "        self.inputs, self.offsets, self.tags = self.load_data()\n",
    "    \n",
    "    def load_data(self):\n",
    "        inputs, offsets, tags = [], [], []\n",
    "            \n",
    "        for word_lst, split_ids in tqdm(data_gen(self.data)):\n",
    "            tokenized = self.cfg.tokenizer.encode_plus(word_lst, \n",
    "                                                       padding='max_length', \n",
    "                                                       truncation=True,\n",
    "                                                       max_length=self.cfg.max_length + 2,  # reserved for cls and sep\n",
    "                                                       return_offsets_mapping=True, \n",
    "                                                       return_tensors='pt',\n",
    "                                                       is_split_into_words=True)\n",
    "            \n",
    "            inputs.append({\"input_ids\": tokenized['input_ids'][0],\n",
    "                           \"token_type_ids\": tokenized['token_type_ids'][0],\n",
    "                           \"attention_mask\": tokenized['attention_mask'][0]\n",
    "                          })\n",
    "            \n",
    "            sentence_word_idx = []\n",
    "            for idx, (start, end) in enumerate(tokenized.offset_mapping[0][1:]):\n",
    "                if start == 0 and end != 0:\n",
    "                    sentence_word_idx.append(idx)\n",
    "            if len(sentence_word_idx) < self.cfg.max_length - 1:\n",
    "                sentence_word_idx.extend([0]* (self.cfg.max_length - len(sentence_word_idx)))\n",
    "            offsets.append(torch.as_tensor(sentence_word_idx))\n",
    "            \n",
    "            # ignore cls for convenience\n",
    "            tag = torch.full(size=(CFG.max_length, ), fill_value=-1, dtype=torch.long)\n",
    "            tag[0:split_ids[-1]+1] = 0\n",
    "            tag[split_ids[:-1]] = 1\n",
    "            \n",
    "            tags.append(tag)  \n",
    "            \n",
    "        return inputs, offsets, tags\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.offsets[idx], self.tags[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1507c24-98b1-47a7-acc8-835a7299f164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20086it [00:38, 525.78it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = EduDataset(CFG, data)\n",
    "\n",
    "eval_iter = DataLoader(dataset, shuffle=False, batch_size=CFG.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "651c673d-d9f6-43e4-9e04-67a3388d49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitby_punct():\n",
    "    eval_iter = DataLoader(dataset, shuffle=False, batch_size=1)\n",
    "\n",
    "    punct_lst = [\"，\", \".\", \"。\", \"!\", \"?\", \"~\", \"...\", \"......\"]\n",
    "    \n",
    "    preds_whole, tags_whole = torch.Tensor(), torch.Tensor()\n",
    "    for batch, (word_lst, _) in zip(eval_iter, data_gen(data)):\n",
    "        preds = torch.zeros_like(batch[-1]).int()\n",
    "        for i, word in enumerate(word_lst[:-1]):\n",
    "            if word in punct_lst and word_lst[i+1] not in punct_lst:\n",
    "                preds[0][i] = 1\n",
    "\n",
    "        preds_whole = torch.cat([preds_whole, preds], dim=0)\n",
    "        tags_whole = torch.cat([tags_whole, batch[-1]], dim=0)\n",
    "\n",
    "    tags_whole = tags_whole.masked_fill(tags_whole==-1, 0)\n",
    "    \n",
    "    # inner split points f1\n",
    "    predictions = preds_whole.view(-1)\n",
    "    labels = tags_whole.view(-1)\n",
    "\n",
    "    pred_detected = (predictions == 1)\n",
    "    label_detected = (labels == 1)\n",
    "    co = pred_detected * (pred_detected == label_detected)\n",
    "    co_sum = sum(co)\n",
    "\n",
    "    if sum(pred_detected) == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = co_sum / sum(pred_detected)\n",
    "    recall = co_sum / sum(label_detected)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    print(f1)\n",
    "    \n",
    "    # single f1\n",
    "    # tags_whole = tags_whole.masked_fill(tags_whole==-1, 0)\n",
    "    labels_single = (tags_whole.sum(1) == 0)\n",
    "    preds_single = (preds_whole.sum(1) == 0)\n",
    "\n",
    "    co = preds_single * (preds_single == labels_single)\n",
    "    co_sum = sum(co)\n",
    "\n",
    "    if sum(preds_single) == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = co_sum / sum(preds_single)\n",
    "    recall = co_sum / sum(labels_single)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "183396f9-1f81-4394-b36d-11051ede7ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6882)\n",
      "tensor(0.9010)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7213/3632176982.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msplitby_punct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# splitby_punct()\n",
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8919388d-bd6a-4b3c-8c33-e5d5e4ecb3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.encoder = AutoModel.from_pretrained(cfg.plm)\n",
    "        self.encoder.resize_token_embeddings(len(cfg.tokenizer))\n",
    "        \n",
    "        self.mlp = nn.Linear(self.encoder.config.hidden_size, cfg.num_labels)\n",
    "        self.dropout = nn.Dropout(cfg.dropout)\n",
    "        \n",
    "    def feat(self, inputs, offsets):\n",
    "        length = torch.sum(inputs[\"attention_mask\"], dim=-1) - 2\n",
    "        \n",
    "        feats, *_ = self.encoder(**inputs, return_dict=False)   # batch_size, seq_len (tokenized), plm_hidden_size\n",
    "           \n",
    "        # remove [CLS] [SEP]\n",
    "        cls_feat = feats[:, :1]\n",
    "        char_feat = torch.narrow(feats, 1, 1, feats.size(1) - 2)\n",
    "        return cls_feat, char_feat, length\n",
    "        \n",
    "    def forward(self, inputs, offsets, tags=None):\n",
    "        cls_feat, char_feat, char_len = self.feat(inputs, offsets)\n",
    "        \n",
    "        word_idx = offsets.unsqueeze(-1).expand(-1, -1, char_feat.shape[-1])  # expand to the size of char feat\n",
    "        word_feat = torch.gather(char_feat, dim=1, index=word_idx)  # embeddings of first char in each word\n",
    "        \n",
    "        feats = self.dropout(word_feat)\n",
    "        logits = self.mlp(feats)\n",
    "        \n",
    "        if tags is not None:\n",
    "            loss = nn.CrossEntropyLoss(reduction='mean', ignore_index=-1)(logits.view(-1, logits.size(-1)), tags.long().view(-1))\n",
    "            return torch.softmax(logits, dim=-1), loss\n",
    "\n",
    "        return torch.softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737d1dd-4553-4427-bbc3-0a90b625621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def metrics_fn(predictions, labels):\n",
    "#     predictions = predictions.view(-1, predictions.size(-1))\n",
    "#     labels = labels.view(-1)\n",
    "    \n",
    "#     pred_detected = (predictions[:, 1] > 0.5)\n",
    "#     label_detected = (labels == 1)\n",
    "#     co = pred_detected * (pred_detected == label_detected)\n",
    "    \n",
    "#     if sum(pred_detected) == 0:\n",
    "#         precision = 0\n",
    "#     else:\n",
    "#         precision = sum(co) / sum(pred_detected)\n",
    "#     recall = sum(co) / sum(label_detected)\n",
    "#     f1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "#     return {\"f1\": f1.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abcad6f-ce6c-4784-bfbf-e8124359f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_fn(predictions, labels):\n",
    "    left = predictions.detach()\n",
    "    right = predictions.detach()\n",
    "    \n",
    "    predictions = predictions.view(-1, predictions.size(-1))\n",
    "    labels = labels.view(-1)\n",
    "    \n",
    "    pred_detected = (predictions[:, 1] > 0.5)\n",
    "    label_detected = (labels == 1)\n",
    "    co = pred_detected * (pred_detected == label_detected)\n",
    "    co_sum = sum(co)\n",
    "    \n",
    "    tolerance = 3\n",
    "    for i in range(tolerance):\n",
    "        left = torch.cat([left, torch.zeros(left.size(0), 1, left.size(2)).int()], dim=1)[:, 1:, :]\n",
    "        right = torch.cat([torch.zeros(left.size(0), 1, left.size(2)).int(), right], dim=1)[:, :-1, :]\n",
    "        \n",
    "        left_flat = left.reshape(-1, left.size(-1))\n",
    "        right_flat = right.reshape(-1, right.size(-1))\n",
    "        \n",
    "        left_detected = (left_flat[:, 1] > 0.5)\n",
    "        right_detected = (right_flat[:, 1] > 0.5)\n",
    "        \n",
    "        co_sum += sum(left_detected * (left_detected == label_detected))\n",
    "        co_sum += sum(right_detected * (right_detected == label_detected))\n",
    "        \n",
    "    if sum(pred_detected) == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = co_sum / sum(pred_detected)\n",
    "    recall = co_sum / sum(label_detected)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    return {\"f1\": f1.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb7b5ae-f7e5-45eb-abe2-52762c24d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_f1(predictions, labels):\n",
    "    print(labels)\n",
    "    labels = labels.masked_fill(labels==-1, 0)\n",
    "    print(labels)\n",
    "    labels_single = (labels.sum(1) == 0)\n",
    "    preds_single = ((predictions[:, :, 1] > 0.5).sum(1) == 0)\n",
    "    print(labels_single)\n",
    "    print((predictions[:, :, 1] > 0.5).sum(1))\n",
    "    \n",
    "    co = preds_single * (preds_single == labels_single)\n",
    "    co_sum = sum(co)\n",
    "    \n",
    "    if sum(preds_single) == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = co_sum / sum(preds_single)\n",
    "    recall = co_sum / sum(labels_single)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    \n",
    "    return {\"f1\": f1.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde6a76-f3dc-4f7b-951c-8f3870cd9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_f1(predictions=logits_whole, labels=tags_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a0d070-2ba7-4ce0-a0e8-7c41072d3702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_fn(predictions=logits_whole, labels=tags_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec041ce-093f-4a42-9164-910f8f5b4456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-electra-180g-large-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "98it [00:56,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Evaluation:\n",
      "-Loss: 0.22451341152191162  F1: 0.14755763113498688 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SegModel(CFG)\n",
    "model.load_state_dict(torch.load(f'/root/autodl-tmp/diag_dep/edu_seg/0/model.bin'))\n",
    "model.to('cuda' if CFG.cuda else 'cpu')\n",
    "model.eval()\n",
    "\n",
    "avg_loss, step = 0.0, 0\n",
    "logits_whole, tags_whole = torch.Tensor(), torch.Tensor()\n",
    "for step, batch in tqdm(enumerate(eval_iter)):\n",
    "    inputs, offsets, tags = batch\n",
    "\n",
    "    if CFG.cuda and torch.cuda.is_available():\n",
    "        inputs_cuda = {}\n",
    "        for key,value in inputs.items():\n",
    "            inputs_cuda[key] = value.cuda()\n",
    "        inputs = inputs_cuda\n",
    "        offsets, tags = to_cuda(data=(offsets, tags))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits, loss = model(inputs, offsets, tags)\n",
    "\n",
    "    logits_whole = torch.cat([logits_whole, logits.cpu()], dim=0)\n",
    "    tags_whole = torch.cat([tags_whole, tags.cpu()], dim=0)\n",
    "\n",
    "    avg_loss += loss * len(tags)  # times the batch size of data\n",
    "\n",
    "metrics = metrics_fn(predictions=logits_whole, labels=tags_whole)\n",
    "\n",
    "avg_loss /= len(eval_iter.dataset)\n",
    "print(\"--Evaluation:\")\n",
    "print(\"-Loss: {}  F1: {} \\n\".format(avg_loss, metrics['f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075b0807-74e2-41d6-b92a-b3edd1795d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('jgy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f5970cc3159b15dedb1f3a2bddfb758e67a1721376b7397fa1f3df8941c2f173"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
