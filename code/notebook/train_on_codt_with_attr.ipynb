{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:50:11.957426: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-08 14:50:11.957463: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.par_with_attr import ParWithAttr\n",
    "from model.base_par import DepParser\n",
    "from utils import arc_rel_loss, uas_las, to_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # domains = ['BC', 'FIN', 'LEG', 'PB', 'PC', 'ZX']\n",
    "    train_file = '../aug/codt_train.conll'\n",
    "    dev_file = '../aug/codt_dev.conll'\n",
    "    domains = ['BC']\n",
    "    # plm = 'hfl/chinese-electra-180g-large-discriminator'\n",
    "    plm = 'hfl/chinese-electra-180g-base-discriminator'\n",
    "    random_seed = 42\n",
    "    num_epochs = 15\n",
    "    # batch_size = 64  # using 22g memory when using electra-large\n",
    "    batch_size = 32\n",
    "    plm_lr = 2e-5\n",
    "    head_lr = 1e-4\n",
    "    weight_decay = 0.01\n",
    "    dropout = 0.2\n",
    "    grad_clip = 2\n",
    "    scheduler = 'linear'\n",
    "    warmup_ratio = 0.1\n",
    "    num_early_stop = 3\n",
    "    max_length = 128\n",
    "    hidden_size = 400\n",
    "    num_labels = 35\n",
    "    gamma = 0.3\n",
    "    alpha = 0.6\n",
    "    beta = 0.9\n",
    "    print_every = 400\n",
    "    eval_every = 800\n",
    "    cuda = True\n",
    "    fp16 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = CFG.domains\n",
    "\n",
    "tags, rels = [], []\n",
    "for domain in domains:\n",
    "    # file = f'suda/train/{domain}-Train-full.conll'\n",
    "    file = CFG.train_file\n",
    "    fp = open(file, encoding='utf-8')\n",
    "    for line in fp.readlines():\n",
    "        # another sentence\n",
    "        if line == '\\n':\n",
    "            continue\n",
    "        line_sp = line.split('\\t')\n",
    "        rels.append(line_sp[7])\n",
    "        tags.append(line_sp[3])\n",
    "    \n",
    "    fp.close()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_dct = {\n",
    "    'root': '根节点',\n",
    "    'sasubj-obj': '同主同宾',\n",
    "    'sasubj': '同主语',\n",
    "    'dfsubj': '不同主语',\n",
    "    'subj': '主语',\n",
    "    'subj-in': '内部主语',\n",
    "    'obj': '宾语',\n",
    "    'pred': '谓语',\n",
    "    'att': '定语',\n",
    "    'adv': '状语',\n",
    "    'cmp': '补语',\n",
    "    'coo': '并列',\n",
    "    'pobj': '介宾',\n",
    "    'iobj': '间宾',\n",
    "    'de': '的',\n",
    "    'adjct': '附加',\n",
    "    'app': '称呼',\n",
    "    'exp': '解释',\n",
    "    'punc': '标点',\n",
    "    'frag': '片段',\n",
    "    'repet': '重复',\n",
    "    # rst\n",
    "    'attr': '归属',\n",
    "    'bckg': '背景',\n",
    "    'cause': '因果',\n",
    "    'comp': '比较',\n",
    "    'cond': '状况',\n",
    "    'cont': '对比',\n",
    "    'elbr': '阐述',\n",
    "    'enbm': '目的',\n",
    "    'eval': '评价',\n",
    "    'expl': '解释-例证',\n",
    "    'joint': '联合',\n",
    "    'manner': '方式',\n",
    "    'rstm': '重申',\n",
    "    'temp': '时序',\n",
    "    # 'tp-chg': '主题变更',\n",
    "    # 'prob-sol': '问题-解决',\n",
    "    # 'qst-ans': '疑问-回答',\n",
    "    # 'stm-rsp': '陈述-回应',\n",
    "    # 'req-proc': '需求-处理',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'root': 0, 'sasubj-obj': 1, 'sasubj': 2, 'dfsubj': 3, 'subj': 4, 'subj-in': 5, 'obj': 6, 'pred': 7, 'att': 8, 'adv': 9, 'cmp': 10, 'coo': 11, 'pobj': 12, 'iobj': 13, 'de': 14, 'adjct': 15, 'app': 16, 'exp': 17, 'punc': 18, 'frag': 19, 'repet': 20, 'attr': 21, 'bckg': 22, 'cause': 23, 'comp': 24, 'cond': 25, 'cont': 26, 'elbr': 27, 'enbm': 28, 'eval': 29, 'expl': 30, 'joint': 31, 'manner': 32, 'rstm': 33, 'temp': 34}\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "rel2id = {}\n",
    "for i, (key, value) in enumerate(rel_dct.items()):\n",
    "    rel2id[key] = i\n",
    "print(rel2id)\n",
    "print(len(rel2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed & Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=CFG.random_seed):\n",
    "    np.random.seed(seed%(2**32-1))\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic =True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dependency():\n",
    "    def __init__(self, idx, word, tag, head, rel):\n",
    "        self.id = idx\n",
    "        self.word = word\n",
    "        self.tag = tag\n",
    "        self.head = head\n",
    "        self.rel = rel\n",
    "\n",
    "    def __str__(self):\n",
    "        # example:  1\t上海\t_\tNR\tNR\t_\t2\tnn\t_\t_\n",
    "        values = [str(self.idx), self.word, \"_\", self.tag, \"_\", \"_\", str(self.head), self.rel, \"_\", \"_\"]\n",
    "        return '\\t'.join(values)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"({self.word}, {self.tag}, {self.head}, {self.rel})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_codt(data_file: str):\n",
    "    # id, form, tag, head, rel\n",
    "#     sentence:List[Dependency] = [Dependency('0', '<root>', '_', '0', '_')]\n",
    "    sentence:List[Dependency] = []\n",
    "\n",
    "    with open(data_file, 'r', encoding='utf-8') as f:\n",
    "        # data example: 1\t上海\t_\tNR\tNR\t_\t2\tnn\t_\t_\n",
    "        for line in f.readlines():\n",
    "            toks = line.split()\n",
    "            if len(toks) == 0:\n",
    "                yield sentence\n",
    "#                 sentence = [Dependency('0', '<root>', '_', '0', '_')]\n",
    "                sentence = []\n",
    "            elif len(toks) == 10:\n",
    "                dep = Dependency(toks[0], toks[1], toks[3], toks[8], toks[9])\n",
    "                sentence.append(dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG.plm)\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rel</th>\n",
       "      <th>rel_name</th>\n",
       "      <th>attribute</th>\n",
       "      <th>example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>根节点</td>\n",
       "      <td>一个句子的根节点，是句子的核心事件的中心词（一般是谓词），如果没有核心，则第一个主要谓语作为...</td>\n",
       "      <td>“你好，我想咨询一下”中，“咨询”是这个句子的核心，而“你 好”只是一句问候语，因此从“咨询...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sasubj-obj</td>\n",
       "      <td>同主语同宾语</td>\n",
       "      <td>两个谓语（一般为两个动词并列）共享主语和宾语，允许主语完全省略。</td>\n",
       "      <td>“有什么问题我能帮你处理或解决呢？”中，“处理”和“解决”的主语都是“我”，宾语是“问题”，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sasubj</td>\n",
       "      <td>同主语</td>\n",
       "      <td>两个谓语共享主语，但是都是不及物动词或具有不同的宾语，允许主语完全省略。</td>\n",
       "      <td>“我帮你问一下”，“帮”和“问”的主语都是我，但显然宾语不同，因此由第一个谓词“帮”发射“同...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dfsubj</td>\n",
       "      <td>不同主语</td>\n",
       "      <td>两个谓语的主语不同。</td>\n",
       "      <td>“你把订单号发一下，我查询一下”，“发”和“查询”就是由不同主语所发出的动作，因此，由“发”...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>subj</td>\n",
       "      <td>主语</td>\n",
       "      <td>主语是谓语动作的发出者，或是谓语动词的承受对象，或谓语是对主语的状态或其他情况的描述。主语通...</td>\n",
       "      <td>“我买了洗衣液”，“我”是“买”这个动作的主体对象，因此由“买”发射一条“主语”弧到“我”。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         rel rel_name  \\\n",
       "0      0        root      根节点   \n",
       "1      1  sasubj-obj   同主语同宾语   \n",
       "2      2      sasubj      同主语   \n",
       "3      3      dfsubj     不同主语   \n",
       "4      4        subj       主语   \n",
       "\n",
       "                                           attribute  \\\n",
       "0  一个句子的根节点，是句子的核心事件的中心词（一般是谓词），如果没有核心，则第一个主要谓语作为...   \n",
       "1                   两个谓语（一般为两个动词并列）共享主语和宾语，允许主语完全省略。   \n",
       "2               两个谓语共享主语，但是都是不及物动词或具有不同的宾语，允许主语完全省略。   \n",
       "3                                         两个谓语的主语不同。   \n",
       "4  主语是谓语动作的发出者，或是谓语动词的承受对象，或谓语是对主语的状态或其他情况的描述。主语通...   \n",
       "\n",
       "                                             example  \n",
       "0  “你好，我想咨询一下”中，“咨询”是这个句子的核心，而“你 好”只是一句问候语，因此从“咨询...  \n",
       "1  “有什么问题我能帮你处理或解决呢？”中，“处理”和“解决”的主语都是“我”，宾语是“问题”，...  \n",
       "2  “我帮你问一下”，“帮”和“问”的主语都是我，但显然宾语不同，因此由第一个谓词“帮”发射“同...  \n",
       "3  “你把订单号发一下，我查询一下”，“发”和“查询”就是由不同主语所发出的动作，因此，由“发”...  \n",
       "4     “我买了洗衣液”，“我”是“买”这个动作的主体对象，因此由“买”发射一条“主语”弧到“我”。  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_df = pd.read_csv('../attribute.csv', sep=',')\n",
    "extra = pd.read_csv('../extra_attribute.csv', sep=',')\n",
    "\n",
    "attr_df = pd.concat([attr_df, extra], axis=0).reset_index()\n",
    "attr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 168])\n"
     ]
    }
   ],
   "source": [
    "attrs = [\n",
    "    attr_df['rel_name'][i] + \n",
    "    '：' +\n",
    "    attr_df['attribute'][i] +\n",
    "    ' 例子：' + \n",
    "    attr_df['example'][i]\n",
    "    for i in range(len(attr_df))\n",
    "]\n",
    "\n",
    "\n",
    "# attrs[21:36] = [\n",
    "#     attrs[i] +\n",
    "#     attr_df['attribute'][2] +\n",
    "#     attr_df['attribute'][3]\n",
    "#     for i in range(21, 36)\n",
    "# ]\n",
    "\n",
    "# print(attrs)\n",
    "\n",
    "attr_tokenized = tokenizer(attrs, return_offsets_mapping=False, padding=True, return_tensors='pt')\n",
    "\n",
    "num_rels, attr_len = attr_tokenized['input_ids'].shape\n",
    "print(attr_tokenized['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special_tokens_dict = {'additional_special_tokens': ['<root>']}\n",
    " \n",
    "# num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "# print('We have added', num_added_toks, 'tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CODTDataset(Dataset):\n",
    "    def __init__(self, cfg, train):\n",
    "        self.train = train\n",
    "        self.cfg = cfg\n",
    "        self.inputs, self.offsets, self.heads, self.rels, self.masks, self.rel_attrs = self.read_data()\n",
    "        \n",
    "    def read_data(self):\n",
    "        inputs, offsets = [], []\n",
    "        tags, heads, rels, masks = [], [], [], []\n",
    "        rel_attrs = []\n",
    "        \n",
    "        for domain in self.cfg.domains:\n",
    "            if self.train:\n",
    "                # file = f'suda/train/{domain}-Train-full.conll'  \n",
    "                file = self.cfg.train_file\n",
    "            else:\n",
    "                # file = f'suda/dev/{domain}-Dev.conll'\n",
    "                file = self.cfg.dev_file\n",
    "            \n",
    "            for deps in tqdm(load_codt(file)):\n",
    "                # another sentence\n",
    "                seq_len = len(deps)\n",
    "                \n",
    "                word_lst = [] \n",
    "                rel_attr = {'input_ids':torch.Tensor(), 'token_type_ids':torch.Tensor(), 'attention_mask':torch.Tensor()}\n",
    "                head_tokens = np.zeros(self.cfg.max_length, dtype=np.int64)  # same as root index is 0, constrainting by mask \n",
    "                rel_tokens = np.zeros(self.cfg.max_length, dtype=np.int64)\n",
    "                mask_tokens = np.zeros(self.cfg.max_length, dtype=np.int64)\n",
    "                for i, dep in enumerate(deps):\n",
    "                    if i == seq_len or i + 1== self.cfg.max_length:\n",
    "                        break\n",
    "                        \n",
    "                    word_lst.append(dep.word)\n",
    "                      \n",
    "                    if dep.head in ['_', '-1'] or int(dep.head) + 1 >= self.cfg.max_length:\n",
    "                        head_tokens[i+1] = 0\n",
    "                        mask_tokens[i+1] = 0\n",
    "                    else:\n",
    "                        head_tokens[i+1] = int(dep.head)\n",
    "                        mask_tokens[i+1] = 1\n",
    "\n",
    "                    rel_tokens[i+1] = rel2id.get(dep.rel, rel2id['adjct'])\n",
    "                \n",
    "                    rel_attr = {\n",
    "                        'input_ids': torch.cat([rel_attr['input_ids'], attr_tokenized['input_ids'][rel2id.get(dep.rel, rel2id['adjct'])].unsqueeze(0)], dim=0),\n",
    "                        'token_type_ids': torch.cat([rel_attr['token_type_ids'], attr_tokenized['token_type_ids'][rel2id.get(dep.rel, rel2id['adjct'])].unsqueeze(0)], dim=0),\n",
    "                        'attention_mask': torch.cat([rel_attr['attention_mask'], attr_tokenized['attention_mask'][rel2id.get(dep.rel, rel2id['adjct'])].unsqueeze(0)], dim=0)\n",
    "                    }\n",
    "                    \n",
    "                # padding\n",
    "                rel_attr = {\n",
    "                    'input_ids': torch.cat([rel_attr['input_ids'], torch.full((self.cfg.max_length - len(deps), attr_len), 0, dtype=torch.long)], dim=0).long(),\n",
    "                    'token_type_ids': torch.cat([rel_attr['token_type_ids'], torch.full((self.cfg.max_length - len(deps), attr_len), 0, dtype=torch.int)], dim=0).int(),\n",
    "                    'attention_mask': torch.cat([rel_attr['attention_mask'], torch.full((self.cfg.max_length - len(deps), attr_len), 0, dtype=torch.int)], dim=0).int()\n",
    "                }\n",
    "                rel_attrs.append(rel_attr)\n",
    "                \n",
    "                tokenized = tokenizer.encode_plus(word_lst, \n",
    "                                                  padding='max_length', \n",
    "                                                  truncation=True,\n",
    "                                                  max_length=self.cfg.max_length, \n",
    "                                                  return_offsets_mapping=True, \n",
    "                                                  return_tensors='pt',\n",
    "                                                  is_split_into_words=True)\n",
    "                inputs.append({\"input_ids\": tokenized['input_ids'][0],\n",
    "                              \"token_type_ids\": tokenized['token_type_ids'][0],\n",
    "                               \"attention_mask\": tokenized['attention_mask'][0]\n",
    "                              })\n",
    "                \n",
    "#                 sentence_word_idx = np.zeros(self.cfg.max_length, dtype=np.int64)\n",
    "                sentence_word_idx = []\n",
    "                for idx, (start, end) in enumerate(tokenized.offset_mapping[0][1:]):\n",
    "                    if start == 0 and end != 0:\n",
    "                        sentence_word_idx.append(idx)\n",
    "#                         sentence_word_idx[idx] = idx\n",
    "                if len(sentence_word_idx) < self.cfg.max_length - 1:\n",
    "                    sentence_word_idx.extend([0]* (self.cfg.max_length - 1 - len(sentence_word_idx)))\n",
    "                offsets.append(torch.as_tensor(sentence_word_idx))\n",
    "                \n",
    "                heads.append(head_tokens)\n",
    "                rels.append(rel_tokens)\n",
    "                masks.append(mask_tokens)\n",
    "                    \n",
    "        return inputs, offsets, heads, rels, masks, rel_attrs\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.offsets[idx], self.heads[idx], self.rels[idx], self.masks[idx], self.rel_attrs[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26090it [00:58, 443.60it/s]\n",
      "974it [00:02, 447.34it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CODTDataset(CFG, train=True)\n",
    "val_dataset = CODTDataset(CFG, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = DataLoader(train_dataset, batch_size=CFG.batch_size)\n",
    "val_iter = DataLoader(val_dataset, batch_size=CFG.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-electra-180g-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at hfl/chinese-electra-180g-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = ParWithAttr(CFG, attr_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # debug\n",
    "# model = model.cuda()\n",
    "# tr_dataloader = DataLoader(train_dataset, batch_size=2)\n",
    "# for batch in tr_dataloader:\n",
    "#     inputs, offsets, heads, rels, masks, rel_attrs = batch\n",
    "    \n",
    "#     # rel_attrs_concat = {}\n",
    "#     # for key, value in rel_attrs.items():\n",
    "#     #     rel_attrs_concat[key] = value.view(-1, value.size()[-1])\n",
    "#     # rel_attrs = rel_attrs_concat\n",
    "    \n",
    "#     inputs_cuda = {}\n",
    "#     for key, value in inputs.items():\n",
    "#         inputs_cuda[key] = value.cuda()\n",
    "#     inputs = inputs_cuda\n",
    "\n",
    "#     offsets, heads, rels, masks = to_cuda(data=(offsets, heads, rels, masks))\n",
    "    \n",
    "#     print(rel_attrs['input_ids'].shape)\n",
    "#     arc_logit, rel_logit, loss = model(inputs, offsets, heads, rels, masks)\n",
    "#     print(loss)\n",
    "\n",
    "#     break\n",
    "    \n",
    "    \n",
    "# assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer():\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 trainset_size,\n",
    "                 loss_fn: Callable, \n",
    "                 metrics_fn: Callable, \n",
    "                 config: Dict) -> None:\n",
    "        self.loss_fn = loss_fn\n",
    "        self.metrics_fn = metrics_fn\n",
    "\n",
    "        plm_params = [p for n,p in model.named_parameters() if 'encoder' in n]\n",
    "        head_params = [p for n,p in model.named_parameters() if 'encoder' not in n]\n",
    "        self.optim = AdamW([{'params': plm_params, 'lr':config.plm_lr}, \n",
    "                            {'params': head_params, 'lr':config.head_lr}], \n",
    "                            lr=config.plm_lr,\n",
    "                            weight_decay=config.weight_decay\n",
    "                          )\n",
    "        \n",
    "        training_step = int(config.num_epochs * (trainset_size / config.batch_size))\n",
    "        warmup_step = int(config.warmup_ratio * training_step)  \n",
    "        self.optim_schedule = get_linear_schedule_with_warmup(optimizer=self.optim, \n",
    "                                                              num_warmup_steps=warmup_step, \n",
    "                                                              num_training_steps=training_step)\n",
    "        self.scaler = torch.cuda.amp.GradScaler(enabled=config.fp16)\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "    def train(self, \n",
    "              model: nn.Module, \n",
    "              train_iter: DataLoader, \n",
    "              val_iter: DataLoader):\n",
    "        model.train()\n",
    "        if self.config.cuda and torch.cuda.is_available():\n",
    "            model.cuda()\n",
    "            pass\n",
    "        \n",
    "        best_res = [0, 0, 0]\n",
    "        early_stop_cnt = 0\n",
    "        best_state_dict = None\n",
    "        step = 0\n",
    "        for epoch in tqdm(range(self.config.num_epochs)):\n",
    "            for batch in train_iter:\n",
    "                inputs, offsets, heads, rels, masks, rel_attrs = batch\n",
    "                \n",
    "                rel_attrs_concat = {}\n",
    "                for key, value in rel_attrs.items():\n",
    "                    rel_attrs_concat[key] = value.view(-1, value.size()[-1])\n",
    "                rel_attrs = rel_attrs_concat\n",
    "                \n",
    "                if self.config.cuda and torch.cuda.is_available():\n",
    "                    inputs_cuda = {}\n",
    "                    for key, value in inputs.items():\n",
    "                        inputs_cuda[key] = value.cuda()\n",
    "                    inputs = inputs_cuda\n",
    "                    \n",
    "                    rel_attrs_cuda = {}\n",
    "                    for key, value in rel_attrs.items():\n",
    "                        rel_attrs_cuda[key] = value.cuda()\n",
    "                    rel_attrs = rel_attrs_cuda\n",
    "    \n",
    "                    offsets, heads, rels, masks = to_cuda(data=(offsets, heads, rels, masks))\n",
    "                \n",
    "                arc_logits, rel_logits, loss = model(inputs, offsets, heads, rels, masks)\n",
    "                \n",
    "                self.optim.zero_grad()\n",
    "                if self.config.cuda and self.config.fp16:\n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    self.scaler.unscale_(self.optim)\n",
    "                else:\n",
    "                    loss.backward()\n",
    "\n",
    "                nn.utils.clip_grad_norm_(filter(lambda p: p.requires_grad, model.parameters()), max_norm=self.config.grad_clip)\n",
    "\n",
    "                if self.config.fp16:\n",
    "                    self.scaler.step(self.optim)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    self.optim.step()\n",
    "                self.optim_schedule.step()\n",
    "\n",
    "                metrics = self.metrics_fn(arc_logits, rel_logits, heads, rels, masks)\n",
    "\n",
    "                if (step) % self.config.print_every == 0:\n",
    "                    print(f\"--epoch {epoch}, step {step}, loss {loss}\")\n",
    "                    print(f\"  {metrics}\")\n",
    "\n",
    "                if val_iter and (step + 1) % self.config.eval_every == 0:\n",
    "                    avg_loss, uas, las = self.eval(model, val_iter)\n",
    "                    res = [avg_loss, uas, las]\n",
    "                    if las > best_res[2]:  # las\n",
    "                        best_res = res\n",
    "                        best_state_dict = model.state_dict()\n",
    "                        early_stop_cnt = 0\n",
    "                    else:\n",
    "                        early_stop_cnt += 1\n",
    "                    print(\"--Best Evaluation: \")\n",
    "                    print(\"-loss: {}  UAS: {}  LAS: {} \\n\".format(*best_res))\n",
    "                    # back to train mode\n",
    "                    model.train()\n",
    "                \n",
    "                if early_stop_cnt >= self.config.num_early_stop:\n",
    "                    print(\"--early stopping, training finished.\")\n",
    "                    return best_res, best_state_dict\n",
    "\n",
    "                step += 1\n",
    "        print(\"--training finished.\")\n",
    "        return best_res, best_state_dict\n",
    "\n",
    "    # eval func\n",
    "    def eval(self, model: nn.Module, eval_iter: DataLoader, save_file: str = \"\", save_title: str = \"\"):\n",
    "        model.eval()\n",
    "\n",
    "        head_whole, rel_whole, mask_whole = torch.Tensor(), torch.Tensor(), torch.Tensor()\n",
    "        arc_logit_whole, rel_logit_whole = torch.Tensor(), torch.Tensor()\n",
    "        avg_loss = 0.0\n",
    "        for step, batch in enumerate(eval_iter):\n",
    "            inputs, offsets, heads, rels, masks, rel_attrs = batch\n",
    "\n",
    "            rel_attrs_concat = {}\n",
    "            for key, value in rel_attrs.items():\n",
    "                rel_attrs_concat[key] = value.view(-1, value.size()[-1])\n",
    "            rel_attrs = rel_attrs_concat\n",
    "\n",
    "            if self.config.cuda and torch.cuda.is_available():\n",
    "                inputs_cuda = {}\n",
    "                for key, value in inputs.items():\n",
    "                    inputs_cuda[key] = value.cuda()\n",
    "                inputs = inputs_cuda\n",
    "\n",
    "                rel_attrs_cuda = {}\n",
    "                for key, value in rel_attrs.items():\n",
    "                    rel_attrs_cuda[key] = value.cuda()\n",
    "                rel_attrs = rel_attrs_cuda\n",
    "\n",
    "                offsets, heads, rels, masks = to_cuda(data=(offsets, heads, rels, masks))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                arc_logits, rel_logits, loss = model(inputs, offsets, heads, rels, masks, evaluate=True)\n",
    "\n",
    "            arc_logit_whole = torch.cat([arc_logit_whole, arc_logits.cpu()], dim=0)\n",
    "            rel_logit_whole = torch.cat([rel_logit_whole, rel_logits.cpu()], dim=0)\n",
    "\n",
    "            head_whole, rel_whole = torch.cat([head_whole, heads.cpu()], dim=0), torch.cat([rel_whole, rels.cpu()], dim=0)\n",
    "            mask_whole = torch.cat([mask_whole, masks.cpu()], dim=0)\n",
    "\n",
    "            avg_loss += loss.item() * len(heads)  # times the batch size of data\n",
    "\n",
    "        metrics = self.metrics_fn(arc_logit_whole, rel_logit_whole, head_whole, rel_whole, mask_whole)\n",
    "        uas, las = metrics['UAS'], metrics['LAS']\n",
    "\n",
    "        avg_loss /= len(eval_iter.dataset)  # type: ignore\n",
    "\n",
    "        print(\"--Evaluation:\")\n",
    "        print(\"Avg Loss: {}  UAS: {}  LAS: {} \\n\".format(avg_loss, uas, las))\n",
    "\n",
    "        if save_file != \"\":\n",
    "            results = [save_title, avg_loss, uas, las]  # type: ignore\n",
    "            results = [str(x) for x in results]\n",
    "            with open(save_file, \"a+\") as f:\n",
    "                f.write(\",\".join(results) + \"\\n\")  # type: ignore\n",
    "\n",
    "        return avg_loss, uas, las  # type: ignore\n",
    "    \n",
    "    def save_results(self, save_file, save_title, results):\n",
    "        saves = [save_title] + results\n",
    "        saves = [str(x) for x in saves]\n",
    "        with open(save_file, \"a+\") as f:\n",
    "            f.write(\",\".join(saves) + \"\\n\")  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgy/.conda/envs/jgy/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--epoch 0, step 0, loss 16.900272369384766\n",
      "  {'UAS': 0.01951219512195122, 'LAS': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:23<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2913/3698491818.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marc_rel_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muas_las\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2913/1486253128.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, train_iter, val_iter)\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0marc_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diag_dep/model/par_with_attr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, offsets, heads, rels, masks, evaluate)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0minput_ctx_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_rel_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marc_logit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_logit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;31m# batch_size, input_seq_len, head_hidden_size = input_feat.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diag_dep/model/par_with_attr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, heads, offsets, evaluate)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# x: batch_size, seq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mcls_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mword_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_feat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# expand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diag_dep/model/par_with_attr.py\u001b[0m in \u001b[0;36mfeat\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# batch_size, seq_len (tokenized), plm_hidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# remove [CLS] [SEP]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m         hidden_states = self.encoder(\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 )\n\u001b[1;32m    584\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    586\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 397\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = MyTrainer(model=model, trainset_size=len(train_dataset), loss_fn=arc_rel_loss, metrics_fn=uas_las, config=CFG)\n",
    "best_res, best_state_dict = trainer.train(model=model, train_iter=train_iter, val_iter=val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_results(save_file='../results/res.txt', save_title='best_res', results=best_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_state_dict, f\"../results/electra_bc_epoch{CFG.num_epochs}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UAS': 0.8868404322949778, 'LAS': 0.794447976266158}\n"
     ]
    }
   ],
   "source": [
    "va_dataloader = DataLoader(val_dataset, batch_size=128)\n",
    "\n",
    "arc_logits, rel_logits = torch.Tensor(), torch.Tensor()\n",
    "heads_whole, rels_whole, masks_whole = torch.Tensor(), torch.Tensor(), torch.Tensor()\n",
    "for batch in va_dataloader:\n",
    "    inputs, offsets, heads, rels, masks, rel_attrs = batch\n",
    "    \n",
    "    inputs_cuda = {}\n",
    "    for key, value in inputs.items():\n",
    "        inputs_cuda[key] = value.cuda()\n",
    "    inputs = inputs_cuda\n",
    "\n",
    "    offsets, heads, rels, masks = to_cuda(data=(offsets, heads, rels, masks))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        arc_logit, rel_logit, similarity = model.predict(inputs, offsets, masks)\n",
    "        # arc_logit, rel_logit, loss = model(inputs, offsets, heads, rels, masks, evaluate=True)\n",
    "        \n",
    "    arc_logits = torch.cat([arc_logits, arc_logit.cpu()])\n",
    "    rel_logits = torch.cat([rel_logits, similarity.cpu()])\n",
    "    \n",
    "    heads_whole = torch.cat([heads_whole, heads.cpu()])\n",
    "    rels_whole = torch.cat([rels_whole, rels.cpu()])\n",
    "    masks_whole = torch.cat([masks_whole, masks.cpu()])\n",
    "\n",
    "print(uas_las(arc_logits=arc_logits,\n",
    "              rel_logits=rel_logits,\n",
    "              arc_gt=heads_whole,  \n",
    "              rel_gt=rels_whole,\n",
    "              mask=masks_whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('jgy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f5970cc3159b15dedb1f3a2bddfb758e67a1721376b7397fa1f3df8941c2f173"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
