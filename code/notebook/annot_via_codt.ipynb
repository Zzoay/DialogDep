{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb7001f6-0580-4cba-bbb3-037c809cddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import *\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a967fe11-29c1-46bb-adae-35f1ebf5c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "857790fc-b057-4f2b-a780-e655b065924c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 14:09:05.871482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, AdamW, get_constant_schedule_with_warmup, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01edc7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from constant import rel2id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7028a7-2cda-4729-aea3-aeda44c0187c",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85399548-59aa-4c8e-bffe-ea2002527357",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "#     domains = ['BC', 'FIN', 'LEG', 'PB', 'PC', 'ZX']\n",
    "    domains = ['BC']\n",
    "    plm = 'hfl/chinese-electra-180g-base-discriminator'\n",
    "    random_seed = 42\n",
    "    num_epochs = 10\n",
    "    batch_size = 64\n",
    "    hidden_size = 400\n",
    "    lr = 2e-5\n",
    "    weight_decay = 0.01\n",
    "    dropout = 0.2\n",
    "    grad_clip = 2\n",
    "    scheduler = 'linear'\n",
    "    warmup_ratio = 0.1\n",
    "    num_early_stop = 10\n",
    "    max_length = 128\n",
    "    fp16 = True\n",
    "    # num_labels = 21\n",
    "    num_labels = 35\n",
    "    cuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7158744b-71eb-430b-8ec8-bc568edf4ea7",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c2a0919-2734-43e7-a27c-418945cfa81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dependency():\n",
    "    def __init__(self, idx, word, tag, head, rel):\n",
    "        self.id = idx\n",
    "        self.word = word\n",
    "        self.tag = tag\n",
    "        self.head = head\n",
    "        self.rel = rel\n",
    "\n",
    "    def __str__(self):\n",
    "        # example:  1\t上海\t_\tNR\tNR\t_\t2\tnn\t_\t_\n",
    "        values = [str(self.idx), self.word, \"_\", self.tag, \"_\", \"_\", str(self.head), self.rel, \"_\", \"_\"]\n",
    "        return '\\t'.join(values)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"({self.word}, {self.tag}, {self.head}, {self.rel})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1114af9c-a746-4b3f-a347-d275df3a89d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_codt(data_file: str):\n",
    "    # id, form, tag, head, rel\n",
    "#     sentence:List[Dependency] = [Dependency('0', '<root>', '_', '0', '_')]\n",
    "    sentence:List[Dependency] = []\n",
    "\n",
    "    with open(data_file, 'r', encoding='utf-8') as f:\n",
    "        # data example: 1\t上海\t_\tNR\tNR\t_\t2\tnn\t_\t_\n",
    "        for line in f.readlines():\n",
    "            toks = line.split()\n",
    "            if len(toks) == 0:\n",
    "                yield sentence\n",
    "#                 sentence = [Dependency('0', '<root>', '_', '0', '_')]\n",
    "                sentence = []\n",
    "            elif len(toks) == 10:\n",
    "                dep = Dependency(toks[0], toks[1], toks[3], toks[6], toks[7])\n",
    "                sentence.append(dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a13155fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG.plm)\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd5b35-1337-4604-a2dc-8edcab0eff3b",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de388bb-81b3-4051-a6c0-2b6a347c2f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-electra-180g-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from model.base_par import DepParser\n",
    "\n",
    "parser = DepParser(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c8587d8-eb06-4578-a716-61037c8a6881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"../results/base_par.pt\"\n",
    "model_path = '../results/few_shot/with_codt/model_shot_50.bin'\n",
    "model_stat_dict = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa48d5d9-0e94-417f-a814-50fa93559436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.load_state_dict(model_stat_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ffb65c-1c2f-4f89-a44c-cba1eea163b4",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb333b7a-04e7-4618-9f5b-fd57b6eab41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = CFG.domains\n",
    "\n",
    "tags, rels = [], []\n",
    "for domain in domains:\n",
    "    file = f'../suda/train/{domain}-Train-full.conll'\n",
    "    fp = open(file, encoding='utf-8')\n",
    "    for line in fp.readlines():\n",
    "        # another sentence\n",
    "        if line == '\\n':\n",
    "            continue\n",
    "        line_sp = line.split('\\t')\n",
    "        rels.append(line_sp[7])\n",
    "        tags.append(line_sp[3])\n",
    "    \n",
    "    fp.close()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6106118c-8fc6-4438-bd11-c3bccfa526cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'root': 0, 'sasubj-obj': 1, 'sasubj': 2, 'dfsubj': 3, 'subj': 4, 'subj-in': 5, 'obj': 6, 'pred': 7, 'att': 8, 'adv': 9, 'cmp': 10, 'coo': 11, 'pobj': 12, 'iobj': 13, 'de': 14, 'adjct': 15, 'app': 16, 'exp': 17, 'punc': 18, 'frag': 19, 'repet': 20, 'attr': 21, 'bckg': 22, 'cause': 23, 'comp': 24, 'cond': 25, 'cont': 26, 'elbr': 27, 'enbm': 28, 'eval': 29, 'expl': 30, 'joint': 31, 'manner': 32, 'rstm': 33, 'temp': 34, 'tp-chg': 35, 'prob-sol': 36, 'qst-ans': 37, 'stm-rsp': 38, 'req-proc': 39}\n"
     ]
    }
   ],
   "source": [
    "print(rel2id)\n",
    "id2rel = list(rel2id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a940c33-3280-4a6a-97fa-6780b0dc01c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"你 好 , 请问 有 什么 我 可以 帮 您 的 吗 ?\"\n",
    "tokenized = tokenizer.encode_plus(text.split(' '), \n",
    "                      return_offsets_mapping=True, \n",
    "                      return_tensors='pt',\n",
    "                      is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "650ed791-a0bf-4ad0-944e-898e73e307ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(tokenizer, text):\n",
    "    word_lst = text.split(' ')\n",
    "    \n",
    "    tokenized = tokenizer.encode_plus(word_lst, \n",
    "                      return_offsets_mapping=True, \n",
    "                      return_tensors='pt',\n",
    "                      is_split_into_words=True)\n",
    "    return list(range(1, len(word_lst)+1)), tokenized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e82cdc8-a754-44e1-b49a-943abed594d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(tokenized):\n",
    "    inputs = {\"input_ids\": tokenized['input_ids'],\n",
    "              \"token_type_ids\": tokenized['token_type_ids'],\n",
    "              \"attention_mask\": tokenized['attention_mask']}    \n",
    "\n",
    "    sentence_word_idx = []\n",
    "    for idx, (start, end) in enumerate(tokenized.offset_mapping[0][1:]):\n",
    "        if start == 0 and end != 0:\n",
    "            sentence_word_idx.append(idx)\n",
    "    return inputs, torch.as_tensor(sentence_word_idx).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15886980-4cfa-493e-b6c5-0595039f7952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parser, inputs, offsets):\n",
    "    with torch.no_grad():\n",
    "        # arc_logit, rel_logit = parser(inputs=inputs, offsets=offsets, heads=None, tags=None, evaluate=True)\n",
    "        arc_logit, rel_logit = parser(inputs=inputs, offsets=offsets, heads=None, rels=None, masks=None, evaluate=True)\n",
    "\n",
    "    arc_logit[:, torch.arange(arc_logit.size()[1]), torch.arange(arc_logit.size()[2])] = -1e4\n",
    "    \n",
    "    heads = arc_logit.argmax(-1)[0]\n",
    "    heads = heads[1:].tolist()\n",
    "    \n",
    "    rels = rel_logit.argmax(-1)[0]\n",
    "    rels = rels[1:].tolist()\n",
    "    \n",
    "    return heads, rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3743b46d-68ee-4ed0-b7d5-3d6717cf3cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_tripples(idcs, heads, rels, id2rel):\n",
    "    tripples = []\n",
    "    for i in range(len(idcs)):\n",
    "        tripples.append((heads[i], id2rel[rels[i]], idcs[i]))\n",
    "    return tripples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "178f29f0-29db-4c94-a321-38af28beded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "idcs, tokenized = tokenize(tokenizer, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae253d94-d28e-4d22-968d-be6e2c4cd9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, offsets = get_inputs(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4b40b73-8fd6-44fa-a507-07455c4863dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "heads, rels = predict(parser, inputs, offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8b16894-f79d-45b4-967a-e9012089512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tripples = output_tripples(idcs, heads, rels, id2rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "854b6c6b-31bb-4c58-b21f-d0c86cca52e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'subj', 1),\n",
       " (0, 'root', 2),\n",
       " (2, 'punc', 3),\n",
       " (2, 'dfsubj', 4),\n",
       " (4, 'obj', 5),\n",
       " (11, 'att', 6),\n",
       " (9, 'subj', 7),\n",
       " (9, 'adv', 8),\n",
       " (11, 'de', 9),\n",
       " (9, 'obj', 10),\n",
       " (5, 'obj', 11),\n",
       " (5, 'adjct', 12),\n",
       " (12, 'punc', 13)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tripples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23a4c698-8ff7-437a-928e-b102778e343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = parser.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a8cc89e-a5e8-49a6-ab8f-25be0aef1309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_annot(in_file, out_file):\n",
    "    fp = open(in_file, 'r', encoding='utf-8')\n",
    "    fw = open(out_file, 'w', encoding='utf-8')\n",
    "    data = json.load(fp)\n",
    "    \n",
    "    for i, d in enumerate(tqdm(data)):\n",
    "        \n",
    "        for turn, dialog in enumerate(d.get('dialog')):\n",
    "            speaker = dialog.get('speaker')\n",
    "\n",
    "            utterance = dialog.get('utterance')\n",
    "            idcs, tokenized = tokenize(tokenizer, utterance)\n",
    "            \n",
    "            inputs, offsets = get_inputs(tokenized)\n",
    "            inputs = {key:value.cuda() for key, value in inputs.items()}\n",
    "            offsets = offsets.cuda()\n",
    "            \n",
    "            heads, rels = predict(parser, inputs, offsets)\n",
    "            \n",
    "            for i in range(len(heads)):\n",
    "                head = f\"{turn}-{heads[i]}\"\n",
    "                tail = f\"{turn}-{idcs[i]}\"\n",
    "                rel = id2rel[rels[i]]\n",
    "                d['relationship'].append([head, rel, tail])\n",
    "        \n",
    "    save_str = json.dumps(data, ensure_ascii=False, indent=4, separators=(',', ': '))\n",
    "    fw.write(save_str)\n",
    "    fp.close()\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d35e77f5-6af2-4f81-993e-0eb5ab1bde8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_annot(in_file='data_testset/test.json', out_file='pre_annot_new/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1f5852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_postproc(parser, word_lst, inputs, offsets):\n",
    "    from constant import rel2id, punct_lst\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # arc_logit, rel_logit = parser(inputs=inputs, offsets=offsets, heads=None, tags=None, evaluate=True)\n",
    "        arc_logit, rel_logit = parser(inputs=inputs, offsets=offsets, heads=None, rels=None, masks=None,evaluate=True)\n",
    "\n",
    "    word_lst.insert(0, '[root]')\n",
    "    arc_logit[:, torch.arange(arc_logit.size()[1]), torch.arange(arc_logit.size()[2])] = -1e4\n",
    "\n",
    "    weak_signals = [\n",
    "    ['说', '表示', '看', '显示', '知道', '认为', '希望', '指出'],\n",
    "    ['如果', '假如', '的话', '若', '如'],\n",
    "    ['因为', '所以', '导致', '因此', '造成', '由于', '因而'],\n",
    "    ['但是', '可是', '但', '竟', '却', '不过', '居然', '而是'],\n",
    "    ['以及', '也', '并', '并且', '又', '或者'],\n",
    "    ['对于', '自从', '之前', '上次'],\n",
    "    ['明天', '晚上', '到时候', '再', '然后', '接下来', '最后', '随后'],\n",
    "    ['为了', '想要', '使', '为 的'],\n",
    "    ['通过', '必须', '点击'],\n",
    "    ['对 吗', '是 吗', '对 吧', '是 吧', '对 ?'],\n",
    "    ['更', '比', '只'],\n",
    "    ['解释', '比如', '例如', '是 这样'],\n",
    "    ['理想', '真 棒', '太 棒', '真差', '太 差', '不 行', '扯皮'],\n",
    "    ]\n",
    "\n",
    "    weak_labels = [\n",
    "        rel2id['attr'],\n",
    "        rel2id['cond'],\n",
    "        rel2id['cause'],\n",
    "        rel2id['cont'],\n",
    "        rel2id['joint'],\n",
    "        rel2id['bckg'],\n",
    "        rel2id['temp'],\n",
    "        rel2id['enbm'],\n",
    "        rel2id['manner'],\n",
    "        rel2id['rstm'],\n",
    "        rel2id['comp'],\n",
    "        rel2id['expl'],\n",
    "        rel2id['eval'],\n",
    "    ]\n",
    "\n",
    "    priority = {\n",
    "        rel2id['cont']: 1,\n",
    "        rel2id['temp']: 2, rel2id['cause']: 2, rel2id['bckg']: 2, rel2id['comp']: 2,\n",
    "        rel2id['joint']: 3, rel2id['attr']: 3,\n",
    "        None: 5,  # 4 is default\n",
    "    }\n",
    "\n",
    "    reverse_by_words = [\n",
    "        '你 好', '您 好',\n",
    "    ]\n",
    "\n",
    "    id2rel = list(rel2id.keys())\n",
    "\n",
    "    origin4change = [rel2id[x] for x in ['root', 'dfsubj', 'sasubj']]\n",
    "\n",
    "    signal_dct = {}\n",
    "    for i, signals in enumerate(weak_signals):\n",
    "        for s in signals:\n",
    "            signal_dct[s] = weak_labels[i]\n",
    "\n",
    "    from constant import rel2id, punct_lst\n",
    "\n",
    "    rel_preds = rel_logit.argmax(-1)\n",
    "    head_preds = arc_logit.argmax(-1)\n",
    "\n",
    "    signals_new_whole = torch.Tensor()\n",
    "    heads_new_whole, rels_new_whole = torch.Tensor(), torch.Tensor()\n",
    "    seq_len = len(word_lst[1:])\n",
    "    if seq_len == 0:\n",
    "        return\n",
    "    \n",
    "    signals = torch.zeros(seq_len+1).int()\n",
    "    heads, rels = torch.full(size=(seq_len+1,), fill_value=-2).int(), torch.zeros(seq_len+1).int()\n",
    "    split, splits, signal  = 1, [], None\n",
    "    for i, word in enumerate(word_lst[:-1]):\n",
    "\n",
    "        if word in signal_dct.keys() and priority.get(signal_dct[word], 4) < priority.get(signal, 4):\n",
    "            signal = signal_dct[word]\n",
    "        if f'{word} {word_lst[i+1]}' in signal_dct.keys() and priority.get(signal_dct[f'{word} {word_lst[i+1]}'], 4) < priority.get(signal, 4):\n",
    "            signal = signal_dct[f'{word} {word_lst[i+1]}']\n",
    "        \n",
    "        if word in punct_lst and word_lst[i+1] not in punct_lst:\n",
    "            if signal is not None and i + 2 - split > 2:  # set 2 to the min length of edu\n",
    "                signals[split:i+2] = signal\n",
    "                signal = None\n",
    "            splits.append(split)\n",
    "            split = i + 2\n",
    "\n",
    "    # add the last data\n",
    "    if i + 1 < seq_len:\n",
    "        word_lst.append(word)\n",
    "\n",
    "    heads = head_preds[0]\n",
    "    # heads.masked_fill_(mask=~masks_whole[sample_idx].bool(), value=-2)\n",
    "\n",
    "    rels = rel_preds[0]\n",
    "    # rels.masked_fill_(mask=~masks_whole[sample_idx].bool(), value=-2)\n",
    "\n",
    "    if split > 1:\n",
    "        splits.append(split)\n",
    "        if signal is not None:\n",
    "            signals[split:i+2] = signal\n",
    "    \n",
    "    splits.append(len(word_lst[1:]))\n",
    "    # when num of 'edu' >= 2, try change rel and head\n",
    "    # if len(splits) > 2:\n",
    "    cnt = -1\n",
    "    for idx, head in enumerate(heads[1:]):\n",
    "        if head == -2:\n",
    "            break\n",
    "        if head == -1:\n",
    "            continue\n",
    "\n",
    "        if len(splits) > 2 and idx + 1 >= splits[cnt+1]:\n",
    "            cnt += 1\n",
    "\n",
    "        if ((len(splits) > 2 and (head < splits[cnt] or head >= splits[cnt+1])) or idx - head > 0) and rels[idx + 1] in origin4change:  # cross 'edu'\n",
    "            if signals[idx+1] != 0:\n",
    "                rels[idx+1] = signals[idx+1]\n",
    "                \n",
    "                if head == 0 and rels[idx + 1] in [rel2id['cond']]:  # reverse\n",
    "                    tmp_heads = heads.clone()\n",
    "                    tmp_heads[:splits[cnt+1]] = 0\n",
    "                    head_idx = [idx + 1]\n",
    "                    tail_idx = (tmp_heads == idx + 1).nonzero()  # find tail index\n",
    "                    if len(tail_idx) == 0:  # ring or fail\n",
    "                        # if 'cont', revsere root; else unchange\n",
    "                        tail_idx = (heads == idx + 1).nonzero() if signals[idx+1] == rel2id['cont'] else [idx + 1]\n",
    "                        head_idx = (heads == idx + 1).nonzero() if head_idx == tail_idx else head_idx\n",
    "                    if len(head_idx) != 0:\n",
    "                        heads[tail_idx[0]] = 0\n",
    "                        heads[head_idx[0]] = tail_idx[0]\n",
    "            elif head != 0:  # default\n",
    "                rels[idx + 1] = rel2id['elbr']\n",
    "\n",
    "            # special cases\n",
    "            if len(splits) > 2 and word_lst[idx+1] == '好' and word_lst[idx] in ['你', '您']:  # reverse\n",
    "                tmp_heads = heads.clone()\n",
    "                tmp_heads[:splits[cnt+1]] = 0\n",
    "                tail_idx = (tmp_heads == idx + 1).nonzero()  # find tail index\n",
    "                if len(tail_idx) != 0:  \n",
    "                    heads[tail_idx[0]] = 0\n",
    "                    heads[idx + 1] = tail_idx[0]\n",
    "                    rels[idx + 1] = rel2id['elbr']\n",
    "\n",
    "            # 'attr' label should be reversed again; below can match most of cases\n",
    "            if splits[cnt] == 1 and rels[idx + 1] in [rel2id['attr']]:\n",
    "                tmp_heads = heads.clone()\n",
    "                tmp_heads[:splits[cnt+1]] = 0\n",
    "                tail_idx = ((tmp_heads != 0) * (tmp_heads >= splits[cnt]) * (tmp_heads < splits[cnt + 1])).nonzero().flatten()\n",
    "                if len(tail_idx) != 0 and rels[tail_idx[0]] in origin4change:\n",
    "                    heads[tail_idx[0]] = idx + 1\n",
    "                    rels[tail_idx[0]] = rels[idx + 1]\n",
    "                else:\n",
    "                    dep_idx = heads[idx + 1].item()\n",
    "                    if dep_idx != 0 and (dep_idx < splits[cnt] or dep_idx > splits[cnt+1]):\n",
    "                        heads[idx + 1] = 0\n",
    "                        heads[dep_idx] = idx + 1\n",
    "                        rels[dep_idx] = rels[idx + 1]\n",
    "\n",
    "    rels.masked_fill_(heads == 0, 0)  # root\n",
    "    heads[0] = 0\n",
    "    heads[1:].masked_fill_(heads[1:] == -2, 0)\n",
    "    \n",
    "    return heads, rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41dce62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_annot_conll(in_file, out_file):\n",
    "    fp = open(in_file, 'r', encoding='utf-8')\n",
    "    fw = open(out_file, 'w', encoding='utf-8')\n",
    "    data = json.load(fp)\n",
    "    \n",
    "    for d in tqdm(data):\n",
    "        \n",
    "        for turn, dialog in enumerate(d.get('dialog')):\n",
    "            speaker = dialog.get('speaker')\n",
    "\n",
    "            utterance = dialog.get('utterance')\n",
    "            idcs, tokenized = tokenize(tokenizer, utterance)\n",
    "            word_lst = utterance.split(' ')\n",
    "            \n",
    "            inputs, offsets = get_inputs(tokenized)\n",
    "            inputs = {key:value.cuda() for key, value in inputs.items()}\n",
    "            offsets = offsets.cuda()\n",
    "            \n",
    "            heads, rels = predict(parser, inputs, offsets)\n",
    "            # print(heads.shape, rels.shape)\n",
    "            for i in range(len(heads)):\n",
    "                head = int(heads[i])\n",
    "                tail = f\"{turn}-{idcs[i]}\"\n",
    "                rel = id2rel[rels[i]]\n",
    "\n",
    "                save_str = f'{i+1}\\t{word_lst[i]}\\t_\\t_\\t_\\t_\\t{head}\\t{rel}\\t_\\t_\\n'\n",
    "                fw.write(save_str)\n",
    "\n",
    "            fw.write('\\n')\n",
    "    fp.close()\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13a0f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_annot_conll_ensemble(in_file, out_file):\n",
    "    fp = open(in_file, 'r', encoding='utf-8')\n",
    "    fw = open(out_file, 'w', encoding='utf-8')\n",
    "    data = json.load(fp)\n",
    "    \n",
    "    CFG.num_labels = 21\n",
    "    parser_1 = DepParser(CFG)\n",
    "    parser_1.load_state_dict(torch.load('../results/base_par.pt'))\n",
    "    parser_1 = parser_1.cuda()\n",
    "\n",
    "    for d in tqdm(data):\n",
    "        \n",
    "        for turn, dialog in enumerate(d.get('dialog')):\n",
    "            speaker = dialog.get('speaker')\n",
    "\n",
    "            utterance = dialog.get('utterance')\n",
    "            idcs, tokenized = tokenize(tokenizer, utterance)\n",
    "            word_lst = utterance.split(' ')\n",
    "            \n",
    "            inputs, offsets = get_inputs(tokenized)\n",
    "            inputs = {key:value.cuda() for key, value in inputs.items()}\n",
    "            offsets = offsets.cuda()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # arc_logit, rel_logit = parser(inputs=inputs, offsets=offsets, heads=None, tags=None, evaluate=True)\n",
    "                arc_logit, rel_logit = parser(inputs=inputs, offsets=offsets, heads=None, rels=None, masks=None,evaluate=True)\n",
    "            arc_logit[:, torch.arange(arc_logit.size()[1]), torch.arange(arc_logit.size()[2])] = -1e4\n",
    "            arc_logit, rel_logit = arc_logit.softmax(-1), rel_logit.softmax(-1)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # arc_logit, rel_logit = parser(inputs=inputs, offsets=offsets, heads=None, tags=None, evaluate=True)\n",
    "                arc_logit_another, rel_logit_another = parser_1(inputs=inputs, offsets=offsets, heads=None, rels=None, masks=None,evaluate=True)\n",
    "            arc_logit_another[:, torch.arange(arc_logit_another.size()[1]), torch.arange(arc_logit_another.size()[2])] = -1e4\n",
    "            arc_logit_another, rel_logit_another = arc_logit_another.softmax(-1), rel_logit_another.softmax(-1)\n",
    "\n",
    "            # soft\n",
    "            # arc_logit *= 0.8\n",
    "            # arc_logit += 0.2 * arc_logit_another\n",
    "            # rel_logit[:, :, :21] *= 0.8\n",
    "            # rel_logit[:, :, :21] += 0.2 * rel_logit_another[:, :, :21]\n",
    "\n",
    "            # hard\n",
    "            arc_logit *= 0.8\n",
    "            arc_logit += torch.where(arc_logit > arc_logit_another, 0.2 * arc_logit, 0.2 * arc_logit_another)\n",
    "            rel_logit *= 0.8\n",
    "            rel_logit[:, :, :21] += torch.where(rel_logit[:, :, :21] > rel_logit_another, 0.2 * rel_logit[:, :, :21], 0.2 * rel_logit_another)\n",
    "\n",
    "            heads = arc_logit.argmax(-1)[0]\n",
    "            rels = rel_logit.argmax(-1)[0]\n",
    "\n",
    "            heads = heads[1:].tolist()\n",
    "            rels = rels[1:].tolist()\n",
    "\n",
    "            # print(heads.shape, rels.shape)\n",
    "            for i in range(len(heads)):\n",
    "                head = int(heads[i])\n",
    "                tail = f\"{turn}-{idcs[i]}\"\n",
    "                rel = id2rel[rels[i]]\n",
    "\n",
    "                save_str = f'{i+1}\\t{word_lst[i]}\\t_\\t_\\t_\\t_\\t{head}\\t{rel}\\t_\\t_\\n'\n",
    "                fw.write(save_str)\n",
    "\n",
    "            fw.write('\\n')\n",
    "    fp.close()\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dd4d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_annot_via_tensor(in_file, out_file):\n",
    "    fp = open(in_file, 'r', encoding='utf-8')\n",
    "    fw = open(out_file, 'w', encoding='utf-8')\n",
    "    data = json.load(fp)\n",
    "    \n",
    "    head_preds, rel_preds = torch.load('../preds/head_preds_ensemble_logit.pt'), torch.load('../preds/rel_preds_ensemble_logit.pt')\n",
    "    for i, d in enumerate(tqdm(data)):\n",
    "        \n",
    "        for turn, dialog in enumerate(d.get('dialog')):\n",
    "            speaker = dialog.get('speaker')\n",
    "\n",
    "            utterance = dialog.get('utterance')\n",
    "            idcs, tokenized = tokenize(tokenizer, utterance)\n",
    "            word_lst = utterance.split(' ')\n",
    "            \n",
    "            inputs, offsets = get_inputs(tokenized)\n",
    "            inputs = {key:value.cuda() for key, value in inputs.items()}\n",
    "            offsets = offsets.cuda()\n",
    "            \n",
    "            # heads, rels = predict(parser, inputs, offsets)\n",
    "            heads, rels = head_preds[i][1:].int(), rel_preds[i][1:].int()\n",
    "            \n",
    "            # print(heads.shape, rels.shape)\n",
    "            for j in range(len(word_lst)):\n",
    "                head = int(heads[j])\n",
    "                # tail = f\"{turn}-{idcs[i]}\"\n",
    "                rel = id2rel[rels[j]]\n",
    "\n",
    "                save_str = f'{j+1}\\t{word_lst[j]}\\t_\\t_\\t_\\t_\\t{head}\\t{rel}\\t_\\t_\\n'\n",
    "                fw.write(save_str)\n",
    "\n",
    "            fw.write('\\n')\n",
    "    fp.close()\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1980401-bee5-475b-870b-6cd0c049d908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 3977/9101 [11:19<14:35,  5.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5660/2577203924.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpre_annot_conll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../data/train_proc.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../aug/diag_train.conll'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5660/4019511948.py\u001b[0m in \u001b[0;36mpre_annot_conll\u001b[0;34m(in_file, out_file)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;31m# print(heads.shape, rels.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5660/1618142327.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(parser, inputs, offsets)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m# arc_logit, rel_logit = parser(inputs=inputs, offsets=offsets, heads=None, tags=None, evaluate=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0marc_logit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_logit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0marc_logit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marc_logit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marc_logit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1e4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diag_dep/model/base_par.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, offsets, heads, rels, masks, evaluate)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# inputs: batch_size, seq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mcls_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mword_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_feat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# expand to the size of char feat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diag_dep/model/base_par.py\u001b[0m in \u001b[0;36mfeat\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# batch_size, seq_len (tokenized), plm_hidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# remove [CLS] [SEP]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m         hidden_states = self.encoder(\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 )\n\u001b[1;32m    584\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    586\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    513\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         )\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jgy/lib/python3.8/site-packages/transformers/activations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pre_annot_conll(in_file='../data/train_proc.json', out_file='../aug/diag_train.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e29b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('jgy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f5970cc3159b15dedb1f3a2bddfb758e67a1721376b7397fa1f3df8941c2f173"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
