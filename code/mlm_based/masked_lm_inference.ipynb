{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05f863ea-b90a-41bb-b711-fe806a2f3c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import *\n",
    "import json\n",
    "from itertools import chain\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, IterableDataset\n",
    "from transformers import AutoTokenizer, AdamW, AutoModel, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe9da27-36d0-4663-a71f-a4099056f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from constant import rel2id, punct_lst, weak_signals, weak_labels\n",
    "from utils import to_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad37c83-79ad-41f8-b882-3a6be5b30ede",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5889476e-10bf-47cf-ab4c-a1b95e01015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # data_file = '../aug/diag_codt_new/diag_train.conll'\n",
    "    # data_file = '../aug/codt/codt_train_fixed.conll'\n",
    "    data_file = '../data_testset/1to800_1108.json'\n",
    "    plm = 'hfl/chinese-electra-180g-base-discriminator'\n",
    "    random_seed = 42\n",
    "    num_epochs = 2\n",
    "    batch_size = 128\n",
    "    plm_lr = 3e-6\n",
    "    head_lr = 5e-6\n",
    "    weight_decay = 0.01\n",
    "    dropout = 0.1\n",
    "    grad_clip = 2\n",
    "    scheduler = 'linear'\n",
    "    warmup_ratio = 0.1\n",
    "    num_early_stop = 3\n",
    "    max_length = 160\n",
    "    hidden_size = 400\n",
    "    num_labels = 35\n",
    "    print_every = 300\n",
    "    eval_every = 600\n",
    "    cuda = True\n",
    "    fp16 = True\n",
    "    debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ecce4b-c209-4404-84d8-67c9c26c4fb4",
   "metadata": {},
   "source": [
    "# Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85317be3-f17f-495f-8cca-db405577d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=CFG.random_seed):\n",
    "    np.random.seed(seed%(2**32-1))\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic =True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6ca258-7edc-4bb9-81bc-22fd030ddef4",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2961646b-4aff-465d-b3e8-e39c03448ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_signals = {\n",
    "                # '但': 36, '但是': 36, \n",
    "                '情况':36, '为什么': 36,\n",
    "                '吗': 37, '?': 37, '什么': 37,\n",
    "                # '呢': 37, '吧': 37,\n",
    "                '请': 39, '麻烦':39, '希望': 39, '让': 39, '咨询': 39}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0dd6e1e-96b9-4903-87a9-7dcb4fe0418e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'说': 21, '表示': 21, '看到': 21, '显示': 21, '知道': 21, '认为': 21, '希望': 21, '指出': 21, '如果': 25, '假如': 25, '的话': 25, '若': 25, '如': 25, '要是': 25, '倘若': 25, '因为': 23, '所以': 23, '导致': 23, '因此': 23, '造成': 23, '由于': 23, '因而': 23, '但是': 26, '可是': 26, '但': 26, '竟': 26, '却': 26, '不过': 26, '居然': 26, '而是': 26, '反而': 26, '以及': 31, '并且': 31, '或者': 31, '对于': 22, '自从': 22, '上次': 22, '明天': 34, '晚上': 34, '到时候': 34, '再': 34, '然后': 34, '接下来': 34, '最后': 34, '随后': 34, '为了': 28, '使': 28, '为 的': 28, '为 了': 28, '通过': 32, '必须': 32, '点击': 32, '对 吗': 33, '是 吗': 33, '对 吧': 33, '是 吧': 33, '对 ?': 33, '别 的': 24, '另外': 24, '解释': 30, '比如': 30, '例如': 30, '是 这样': 30, '理想': 29, '真 棒': 29, '太 棒': 29, '真差': 29, '太 差': 29, '不 行': 29, '扯皮': 29, '这么 麻烦': 29} 71\n",
      "{'说': 21, '表示': 21, '看到': 21, '显示': 21, '知道': 21, '认为': 21, '希望': 39, '指出': 21, '如果': 25, '假如': 25, '的话': 25, '若': 25, '如': 25, '要是': 25, '倘若': 25, '因为': 23, '所以': 23, '导致': 23, '因此': 23, '造成': 23, '由于': 23, '因而': 23, '但是': 26, '可是': 26, '但': 26, '竟': 26, '却': 26, '不过': 26, '居然': 26, '而是': 26, '反而': 26, '以及': 31, '并且': 31, '或者': 31, '对于': 22, '自从': 22, '上次': 22, '明天': 34, '晚上': 34, '到时候': 34, '再': 34, '然后': 34, '接下来': 34, '最后': 34, '随后': 34, '为了': 28, '使': 28, '为 的': 28, '为 了': 28, '通过': 32, '必须': 32, '点击': 32, '对 吗': 33, '是 吗': 33, '对 吧': 33, '是 吧': 33, '对 ?': 33, '别 的': 24, '另外': 24, '解释': 30, '比如': 30, '例如': 30, '是 这样': 30, '理想': 29, '真 棒': 29, '太 棒': 29, '真差': 29, '太 差': 29, '不 行': 29, '扯皮': 29, '这么 麻烦': 29, '情况': 36, '为什么': 36, '吗': 37, '?': 37, '什么': 37, '请': 39, '麻烦': 39, '让': 39, '咨询': 39} 80\n"
     ]
    }
   ],
   "source": [
    "origin4change = [rel2id[x] for x in ['root', 'dfsubj', 'sasubj']]\n",
    "origin4change.extend([i for i in range(21, 35)])\n",
    "\n",
    "signal_dct = {}\n",
    "for i, signals in enumerate(weak_signals):\n",
    "    for s in signals:\n",
    "        signal_dct[s] = weak_labels[i]\n",
    "print(signal_dct, len(signal_dct.keys()))\n",
    "\n",
    "with_inter = True\n",
    "if with_inter:\n",
    "    signal_dct.update(inter_signals)\n",
    "    print(signal_dct, len(signal_dct.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fe3103d-66cd-4cd7-bafb-c6a8d2db6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dependency():\n",
    "    def __init__(self, idx, word, head, rel):\n",
    "        self.id = idx\n",
    "        self.word = word\n",
    "        self.head = head\n",
    "        self.rel = rel\n",
    "\n",
    "    def __str__(self):\n",
    "        # example:  1\t上海\t_\tNR\tNR\t_\t2\tnn\t_\t_\n",
    "        values = [str(self.idx), self.word, \"_\", \"_\", \"_\", \"_\", str(self.head), self.rel, \"_\", \"_\"]\n",
    "        return '\\t'.join(values)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"({self.word}, {self.head}, {self.rel})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3521966d-6221-4354-a796-21aca80cb9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_lst, sample = [], []\n",
    "# with open(CFG.data_file, 'r', encoding='utf-8') as f:\n",
    "#     for line in f.readlines():\n",
    "#         toks = line.strip().split('\\t')\n",
    "#         if len(toks) == 1:\n",
    "#             sample_lst.append(sample)\n",
    "#             sample = []\n",
    "#             continue\n",
    "        \n",
    "#         sample.append(Dependency(int(toks[0]), toks[1], toks[6], toks[7]))  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "581edebe-c8f1-4e75-8229-c7600d64dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lst = []\n",
    "with open(CFG.data_file, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "for d in data:\n",
    "    rel_dct = {}\n",
    "    for tripple in d['relationship']:\n",
    "        head, rel, tail = tripple\n",
    "        head_uttr_idx, head_word_idx = [int(x) for x in head.split('-')]\n",
    "        tail_uttr_idx, tail_word_idx = [int(x) for x in tail.split('-')]\n",
    "        if head_uttr_idx != tail_uttr_idx:\n",
    "            continue\n",
    "\n",
    "        if not rel_dct.get(head_uttr_idx, None):\n",
    "            rel_dct[head_uttr_idx] = {tail_word_idx: [head_word_idx, rel]}\n",
    "        else:\n",
    "            rel_dct[head_uttr_idx][tail_word_idx] = [head_word_idx, rel]\n",
    "            \n",
    "    for item in d['dialog']:\n",
    "        turn = item['turn']\n",
    "        utterance = item['utterance']\n",
    "        # dep_lst:List[Dependency] = [Dependency(0, '[root]', -1, '_')]\n",
    "        sample:List[Dependency] = []\n",
    "\n",
    "        for word_idx, word in enumerate(utterance.split(' ')):\n",
    "            head_word_idx, rel = rel_dct[turn].get(word_idx + 1, [word_idx, 'adjct'])  # some word annoted missed, padded with last word and 'adjct'\n",
    "            sample.append(Dependency(word_idx + 1, word, head_word_idx, rel))  # start from 1\n",
    "\n",
    "        sample_lst.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d94ddb7-c2b5-413f-aea8-c86c79a9141e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20086/20086 [00:00<00:00, 55713.69it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "edu_lst = []\n",
    "for sample in tqdm(sample_lst):\n",
    "    edu, label = [], []\n",
    "    for i, dep in enumerate(sample[:-1]):\n",
    "        word = dep.word\n",
    "        rel = dep.rel\n",
    "        \n",
    "        edu.append(dep)\n",
    "        \n",
    "        if f'{word} {sample[i+1].word}' in signal_dct.keys():\n",
    "            label.append(f'{word}{sample[i+1].word}')\n",
    "            # if random.random() < 0.9:  # drop\n",
    "            #     edu.pop(-1)\n",
    "        elif word in signal_dct.keys():\n",
    "            label.append(word)\n",
    "            # if random.random() < 0.9:\n",
    "            #     edu.pop(-1)\n",
    "        \n",
    "        # 'edu'\n",
    "        if word in punct_lst:\n",
    "            # if len(label) == 0 and random.random() < 0.5:  # drop\n",
    "            #     edu, label = [], []\n",
    "            #     continue\n",
    "            edu_lst.append(edu)\n",
    "            labels.append(label)                                \n",
    "            edu, label = [], []\n",
    "    \n",
    "    if len(sample) > 1:\n",
    "        edu.append(sample[-1])\n",
    "        if sample[-1].word in signal_dct.keys():\n",
    "            label.append(word)\n",
    "    \n",
    "    # if len(label) == 0 and random.random() < 0.5:\n",
    "    #     continue\n",
    "        \n",
    "    edu_lst.append(edu)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7072713e-0caa-41b1-8063-ccfe776063c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8245 20444\n"
     ]
    }
   ],
   "source": [
    "pos_cnt, neg_cnt = 0, 0\n",
    "for label in labels:\n",
    "    if len(label) != 0:\n",
    "        pos_cnt += 1\n",
    "    else:\n",
    "        neg_cnt += 1\n",
    "        \n",
    "print(pos_cnt, neg_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82f0c554-2275-46d7-81b8-1826dabdf25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21128\n",
      "EOS: 100\n",
      "add token: [root] 21128\n",
      "add token: [qst] 21129\n",
      "add token: [ans] 21130\n",
      "add token: [none] 21131\n",
      "21132\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG.plm)\n",
    "print(len(tokenizer))\n",
    "\n",
    "num_added_toks = tokenizer.add_tokens(['[root]', '[qst]', '[ans]', '[none]'], special_tokens=True)\n",
    "\n",
    "tokenizer.eos_token = '[EOS]'\n",
    "print(f'EOS: {tokenizer.eos_token_id}')\n",
    "\n",
    "tokenizer.root_token = '[root]'\n",
    "tokenizer.root_token_ids = tokenizer('[root]')['input_ids'][1]\n",
    "print(f\"add token: {tokenizer.root_token} {tokenizer.root_token_ids}\")\n",
    "\n",
    "tokenizer.qst_token = '[qst]'\n",
    "tokenizer.qst_token_ids = tokenizer('[qst]')['input_ids'][1]\n",
    "print(f\"add token: {tokenizer.qst_token} {tokenizer.qst_token_ids}\")\n",
    "\n",
    "tokenizer.ans_token = '[ans]'\n",
    "tokenizer.ans_token_ids = tokenizer('[ans]')['input_ids'][1]\n",
    "print(f\"add token: {tokenizer.ans_token} {tokenizer.ans_token_ids}\")\n",
    "\n",
    "tokenizer.none_token = '[none]'\n",
    "tokenizer.none_token_ids = tokenizer('[none]')['input_ids'][1]\n",
    "print(f\"add token: {tokenizer.none_token} {tokenizer.none_token_ids}\")\n",
    "\n",
    "# tokenizer.signal_token = '[signal]'\n",
    "# tokenizer.signal_token_ids = tokenizer('[signal]')['input_ids'][1]\n",
    "# print(f\"add token: {tokenizer.signal_token} {tokenizer.signal_token_ids}\")\n",
    "\n",
    "print(len(tokenizer))\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "391cdd45-b0c7-40b5-bc1d-eeb093d17372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EduDataset(Dataset):\n",
    "#     def __init__(self, cfg, train, prompt, edu_lst, labels=None):\n",
    "#         self.train = train\n",
    "#         self.cfg = cfg\n",
    "#         self.prompt = prompt\n",
    "    \n",
    "#         self.inference = True if labels is None else False\n",
    "        \n",
    "#         if self.inference: \n",
    "#             self.inputs, self.heads, self.rels, self.masks = self.read_data(edu_lst)\n",
    "#         else:\n",
    "#             self.inputs, self.heads, self.rels, self.labels, self.masks = self.read_data(edu_lst, labels)\n",
    "        \n",
    "#     def read_data(self, edu_lst, labels=None):\n",
    "#         inputs, offsets = [], []\n",
    "#         tags, heads, rels, masks = [], [], [], []\n",
    "        \n",
    "#         if labels is None:\n",
    "#             labels = [[] for i in range(len(edu_lst))]\n",
    "#         ans_word_len = 3\n",
    "#         answer_words = []\n",
    "        \n",
    "#         for deps, label in tqdm(zip(edu_lst, labels)):\n",
    "#             seq_len = len(deps)\n",
    "\n",
    "#             word_lst = [] \n",
    "#             rel_attr = {'input_ids':torch.Tensor(), 'token_type_ids':torch.Tensor(), 'attention_mask':torch.Tensor()}\n",
    "#             head_tokens = np.zeros(self.cfg.max_length, dtype=np.int64)  # same as root index is 0, constrainting by mask \n",
    "#             rel_tokens = np.zeros(self.cfg.max_length, dtype=np.int64)\n",
    "#             mask_tokens = np.zeros(self.cfg.max_length, dtype=np.int64)\n",
    "#             ans_tokens = torch.zeros((ans_word_len, len(self.cfg.tokenizer)))\n",
    "#             for i, dep in enumerate(deps):\n",
    "#                 if i == seq_len or i + 1== self.cfg.max_length:\n",
    "#                     break\n",
    "\n",
    "#                 word_lst.append(dep.word)\n",
    "\n",
    "#                 if dep.head in ['_', '-1'] or int(dep.head) + 1 >= self.cfg.max_length:\n",
    "#                     head_tokens[i+1] = 0\n",
    "#                     mask_tokens[i+1] = 0\n",
    "#                 else:\n",
    "#                     head_tokens[i+1] = int(dep.head)\n",
    "#                     mask_tokens[i+1] = 1\n",
    "\n",
    "#                 if self.train:\n",
    "#                     rel_tokens[i+1] = rel2id[dep.rel]\n",
    "#                 else:\n",
    "#                     rel_tokens[i+1] = rel2id.get(dep.rel, rel2id['adjct'])\n",
    "            \n",
    "#             word_lst = self.prompt.split(' ') + ['[SEP]'] + word_lst\n",
    "            \n",
    "#             tokenized = self.cfg.tokenizer.encode_plus(word_lst, \n",
    "#                                                       padding='max_length', \n",
    "#                                                       truncation=True,\n",
    "#                                                       max_length=self.cfg.max_length, \n",
    "#                                                       return_offsets_mapping=True, \n",
    "#                                                       return_tensors='pt',\n",
    "#                                                       is_split_into_words=True)\n",
    "#             inputs.append({\"input_ids\": tokenized['input_ids'][0],\n",
    "#                           \"token_type_ids\": tokenized['token_type_ids'][0],\n",
    "#                            \"attention_mask\": tokenized['attention_mask'][0]\n",
    "#                           })\n",
    "            \n",
    "#             if ~self.inference:\n",
    "#                 if len(label) == 0:\n",
    "#                     ans_tokens[0:ans_word_len, self.cfg.tokenizer.none_token_ids] = 1\n",
    "#                 else: \n",
    "#                     for l in label[0]:  # first label\n",
    "#                         label_id = self.cfg.tokenizer(l)['input_ids'][1:-1]\n",
    "#                         ans_tokens[torch.arange(len(label_id)), label_id] = 1\n",
    "#                         if len(label_id) < ans_word_len:\n",
    "#                             ans_tokens[torch.arange(len(label_id), ans_word_len), self.cfg.tokenizer.eos_token_id] = 1  # padding\n",
    "            \n",
    "#             # ans_tokens /= ans_tokens.sum(-1).unsqueeze(-1).expand(-1, len(self.cfg.tokenizer))\n",
    "#                 answer_words.append(ans_tokens)\n",
    "\n",
    "#             heads.append(head_tokens)\n",
    "#             rels.append(rel_tokens)\n",
    "#             masks.append(mask_tokens)\n",
    "        \n",
    "#         if self.inference:\n",
    "#             return inputs, heads, rels, masks\n",
    "#         return inputs, heads, rels, answer_words, masks\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.inputs[idx], self.heads[idx], self.rels[idx], self.labels[idx], self.masks[idx]\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f8d658b-5330-46f7-a0c7-0671bdcd0410",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EduDataset(IterableDataset):\n",
    "    def __init__(self, cfg, train, prompt, edu_lst, labels):\n",
    "        self.train = train\n",
    "        self.cfg = cfg\n",
    "        self.prompt = prompt\n",
    "        self.edu_lst = edu_lst\n",
    "        self.labels = labels\n",
    "        \n",
    "    def read_data(self, edu_lst, labels):\n",
    "        inputs, offsets = [], []\n",
    "        tags, heads, rels, masks = [], [], [], []\n",
    "        \n",
    "        ans_word_len = 3\n",
    "        answer_words = []\n",
    "        \n",
    "        for deps, label in zip(edu_lst, labels):\n",
    "            seq_len = len(deps)\n",
    "\n",
    "            word_lst = [] \n",
    "            rel_attr = {'input_ids':torch.Tensor(), 'token_type_ids':torch.Tensor(), 'attention_mask':torch.Tensor()}\n",
    "            head_tokens = np.zeros(self.cfg.max_length, dtype=np.int64)  # same as root index is 0, constrainting by mask \n",
    "            rel_tokens = np.zeros(self.cfg.max_length, dtype=np.int64)\n",
    "            mask_tokens = np.zeros(self.cfg.max_length, dtype=np.int64)\n",
    "            ans_tokens = torch.zeros((ans_word_len, len(self.cfg.tokenizer)))\n",
    "            for i, dep in enumerate(deps):\n",
    "                if i == seq_len or i + 1== self.cfg.max_length:\n",
    "                    break\n",
    "\n",
    "                word_lst.append(dep.word)\n",
    "\n",
    "                if dep.head in ['_', '-1'] or int(dep.head) + 1 >= self.cfg.max_length:\n",
    "                    head_tokens[i+1] = 0\n",
    "                    mask_tokens[i+1] = 0\n",
    "                else:\n",
    "                    head_tokens[i+1] = int(dep.head)\n",
    "                    mask_tokens[i+1] = 1\n",
    "\n",
    "                if self.train:\n",
    "                    rel_tokens[i+1] = rel2id[dep.rel]\n",
    "                else:\n",
    "                    rel_tokens[i+1] = rel2id.get(dep.rel, rel2id['adjct'])\n",
    "\n",
    "            word_lst = self.prompt.split(' ') + ['[SEP]'] + word_lst\n",
    "            \n",
    "            tokenized = self.cfg.tokenizer.encode_plus(word_lst, \n",
    "                                              padding='max_length', \n",
    "                                              truncation=True,\n",
    "                                              max_length=self.cfg.max_length, \n",
    "                                              return_offsets_mapping=False, \n",
    "                                              return_tensors='pt',\n",
    "                                              is_split_into_words=True)\n",
    "            tokenized = {\"input_ids\": tokenized['input_ids'][0],\n",
    "                          \"token_type_ids\": tokenized['token_type_ids'][0],\n",
    "                           \"attention_mask\": tokenized['attention_mask'][0]\n",
    "                          }\n",
    "            \n",
    "            if len(label) == 0:\n",
    "                ans_tokens[0:ans_word_len, self.cfg.tokenizer.none_token_ids] = 1\n",
    "            else: \n",
    "                # label_id = self.cfg.tokenizer(l)['input_ids'][1:-1]\n",
    "                label_id = label2id[label[0]]  # first label\n",
    "                if len(label_id) > ans_word_len:\n",
    "                    label_id = label_id[:ans_word_len]\n",
    "                ans_tokens[torch.arange(len(label_id)), label_id] = 1\n",
    "                if len(label_id) < ans_word_len:\n",
    "                    ans_tokens[torch.arange(len(label_id), ans_word_len), self.cfg.tokenizer.eos_token_id] = 1  # padding\n",
    "            \n",
    "            answer_words.append(ans_tokens)\n",
    "\n",
    "            heads.append(head_tokens)\n",
    "            rels.append(rel_tokens)\n",
    "            masks.append(mask_tokens)\n",
    "                    \n",
    "            yield tokenized, head_tokens, rel_tokens, ans_tokens, mask_tokens\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.read_data(self.edu_lst, self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed360646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 5543, 6134, 4385, 5063, 4995, 6427,  721,  928, 1384, 4638, 6404,\n",
      "         3221, 8038,  103,  103,  103,  102]])\n",
      "[14, 15, 16]\n"
     ]
    }
   ],
   "source": [
    "prompt = '能 表现 篇章 语义 信号 的 词 是 ： [MASK] [MASK] [MASK]'\n",
    "prompt_tokenized = CFG.tokenizer.encode_plus(prompt.split(' '), is_split_into_words=True, return_tensors='pt')\n",
    "print(prompt_tokenized['input_ids'])\n",
    "\n",
    "masked_idx = [x[1].item() for x in (prompt_tokenized['input_ids'] == CFG.tokenizer.mask_token_id).nonzero()]\n",
    "CFG.masked_idx = masked_idx\n",
    "print(masked_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ec821da-5e8a-45b7-bbdd-cce5472d56e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    dataset = EduDataset(CFG, True, prompt, edu_lst[:3000], labels[:3000])\n",
    "else:\n",
    "    dataset = EduDataset(CFG, True, prompt, edu_lst, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5c2210f-9769-4252-8a15-4161b220d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(dataset, '../data_saved/mlm/diag_codt/dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76dd33eb-7e6f-4cda-86a3-d31615003b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = torch.load('/root/autodl-tmp/data/sdiag_codt/dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87bde112-032a-4227-b358-3fa552e86ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit = torch.randn(2, len(CFG.tokenizer))\n",
    "# gt = dataset[0][-2]\n",
    "\n",
    "# print(logit.shape)\n",
    "# print(gt.shape)\n",
    "\n",
    "# F.cross_entropy(logit, gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cdba37",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df37d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "    \n",
    "        self.encoder = AutoModel.from_pretrained(cfg.plm)\n",
    "        self.encoder.resize_token_embeddings(len(cfg.tokenizer))\n",
    "\n",
    "        self.mlm_head = nn.Linear(self.encoder.config.hidden_size, len(cfg.tokenizer))\n",
    "\n",
    "        self.dropout = nn.Dropout(cfg.dropout)\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        feats, *_ = self.encoder(**inputs, return_dict=False)   # batch_size, seq_len (tokenized), plm_hidden_size\n",
    "        feats = self.dropout(feats)\n",
    "\n",
    "        masked_feats = feats[:, self.cfg.masked_idx, :]   # batch_size, masked_len, plm_hidden_size\n",
    "\n",
    "        logit = self.mlm_head(masked_feats)  # batch_size, masked_len, vocab_size\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = F.cross_entropy(logit, labels)  # labels: [batch_size, masked_len, vocab_size]\n",
    "            return logit, loss\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "552e85f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-electra-180g-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PromptModel(CFG)\n",
    "\n",
    "model.load_state_dict(torch.load('../results/prompt_model_diag.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bba99fc",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b10da4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = DataLoader(dataset, batch_size=CFG.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a43ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.cuda()\n",
    "\n",
    "# labels_whole, masks_whole = torch.Tensor(), torch.Tensor()\n",
    "# logits = torch.Tensor()\n",
    "# for batch in tqdm(data_iter):\n",
    "#     inputs, heads, rels, labels, masks = batch\n",
    "\n",
    "#     if CFG.cuda and torch.cuda.is_available():\n",
    "#         inputs_cuda = {}\n",
    "#         for key, value in inputs.items():\n",
    "#             inputs_cuda[key] = value.squeeze(1).cuda()\n",
    "#         inputs = inputs_cuda\n",
    "        \n",
    "#         heads, rels, labels, masks = to_cuda(data=(heads, rels, labels, masks))\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         logit = model(inputs, labels=None)\n",
    "        \n",
    "#     logits = torch.cat([logits, logit.cpu()], dim=0)\n",
    "#     labels_whole = torch.cat([labels_whole, labels.cpu()], dim=0)\n",
    "#     masks_whole = torch.cat([masks_whole, masks.cpu()], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4a74625-9693-43fb-8d54-a1b8f004ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = F.cross_entropy(logits.view(-1, labels_whole.size()[-1]), labels_whole.view(-1, labels_whole.size()[-1]), reduction='none')\n",
    "# loss = loss.view(labels_whole.size()[0], labels_whole.size()[1])\n",
    "# print(loss.shape)\n",
    "\n",
    "# loss = loss.sum(1).mean()\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "418d8e6d-50c2-4eea-b5f6-a8bd45d48046",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{21: [0, 1, 2, 3, 4, 5, 7], 39: [6, 76, 77, 78, 79], 25: [8, 9, 10, 11, 12, 13, 14], 23: [15, 16, 17, 18, 19, 20, 21], 26: [22, 23, 24, 25, 26, 27, 28, 29, 30], 31: [31, 32, 33], 22: [34, 35, 36], 34: [37, 38, 39, 40, 41, 42, 43, 44], 28: [45, 46, 47, 48], 32: [49, 50, 51], 33: [52, 53, 54, 55, 56], 24: [57, 58], 30: [59, 60, 61, 62], 29: [63, 64, 65, 66, 67, 68, 69, 70], 36: [71, 72], 37: [73, 74, 75], 27: [80]}\n",
      "[21, 39, 25, 23, 26, 31, 22, 34, 28, 32, 33, 24, 30, 29, 36, 37, 27]\n"
     ]
    }
   ],
   "source": [
    "signal2slices = {}\n",
    "id2pred = []\n",
    "\n",
    "tmp = -1\n",
    "for i, (signal, id) in enumerate(signal_dct.items()):\n",
    "    # if tmp != -1 and id != tmp:\n",
    "    #     signal2slices[tmp].append(i)\n",
    "    if len(signal2slices.get(id, [])) == 0:\n",
    "        signal2slices[id] = [i]\n",
    "        id2pred.append(id)\n",
    "        tmp = id\n",
    "    else:\n",
    "        signal2slices[id].append(i)\n",
    "# signal2slices[id].append(i)\n",
    "signal2slices[27] = [len(signal_dct.items())]\n",
    "id2pred.append(27)\n",
    "\n",
    "print(signal2slices)\n",
    "print(id2pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56f275b6-16e0-46be-bb63-795d3c72365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "939f970d-91e4-45af-9057-5882725be89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    tokenized = tokenizer.encode_plus(x, \n",
    "                                      padding='max_length', \n",
    "                                      truncation=True,\n",
    "                                      max_length=CFG.max_length, \n",
    "                                      return_offsets_mapping=False, \n",
    "                                      return_tensors='pt',\n",
    "                                      is_split_into_words=True)\n",
    "\n",
    "    inputs_cuda = {}\n",
    "    for key, value in tokenized.items():\n",
    "        if key != 'offset_mapping':\n",
    "            inputs_cuda[key] = value.cuda()\n",
    "    tokenized = inputs_cuda\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(tokenized)\n",
    "\n",
    "    sim = (output.view(output.size()[0], -1) @ targets).cpu()[0].softmax(-1)\n",
    "    # print(sim)\n",
    "    # sims = torch.cat([sims, sim.cpu()], dim=0)\n",
    "    \n",
    "    max_probs, max_is = [0.05, 0.05], [27, 38]\n",
    "    for i, (k, v) in enumerate(signal2slices.items()):\n",
    "        prob = sim[v].sum() / len(v)\n",
    "        # prob = sim[0][v[:2]].sum() / 2\n",
    "        \n",
    "        if id2pred[i] < 35 and prob > max_probs[0]:\n",
    "            max_probs[0] = prob\n",
    "            max_is[0] = id2pred[i]\n",
    "        elif prob > max_probs[1]:\n",
    "            max_probs[1] = prob\n",
    "            max_is[1] = id2pred[i]\n",
    "#         if prob > max_probs[1]:\n",
    "#             max_probs[1] = prob\n",
    "#             max_is[1] = i\n",
    "            \n",
    "#             if prob > max_probs[0]:\n",
    "#                 max_probs[0], max_probs[1] = max_probs[1], max_probs[0]\n",
    "#                 max_is[0], max_is[1] = max_is[1], max_is[0]\n",
    "    \n",
    "    # pred = id2pred[max_i]\n",
    "    first, second = max_is[0], max_is[1]\n",
    "    return first, second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "90759984-0028-4253-bcad-dadfdf0caca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([81, 3, 21132])\n"
     ]
    }
   ],
   "source": [
    "ans_word_len = 3\n",
    "targets = torch.Tensor()\n",
    "for key in signal_dct.keys():\n",
    "    target = torch.zeros(ans_word_len, len(CFG.tokenizer)).int()\n",
    "    t = CFG.tokenizer(key)['input_ids'][1:-1]\n",
    "    if len(t) > ans_word_len:\n",
    "        t = t[:ans_word_len]\n",
    "    target[torch.arange(len(t)), t] = 1\n",
    "    if len(t) < ans_word_len:\n",
    "        target[torch.arange(len(t), ans_word_len), CFG.tokenizer.eos_token_id] = 1\n",
    "    targets = torch.cat([targets, target.unsqueeze(0)], dim=0)\n",
    "    \n",
    "target = torch.zeros(ans_word_len, len(CFG.tokenizer)).int()\n",
    "target[0:ans_word_len, CFG.tokenizer.none_token_ids] = 1\n",
    "targets = torch.cat([targets, target.unsqueeze(0)], dim=0)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "520ea30a-05b2-4f35-81be-cf994d5a702f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 201/20086 [00:02<04:10, 79.46it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_756/1713648472.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'[SEP]'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mword_lst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0msignal1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;31m# preds = torch.cat([preds, torch.tensor([pred])], dim=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_756/1736671667.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_756/622417942.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, labels)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# batch_size, seq_len (tokenized), plm_hidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         hidden_states = self.encoder(\n\u001b[0m\u001b[1;32m    917\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 )\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    585\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2926\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2928\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# preds = torch.Tensor()\n",
    "f = open('/root/autodl-tmp/output.conll', 'w+', encoding='utf-8')\n",
    "\n",
    "targets = targets.view(targets.size()[0], -1).T.cuda()\n",
    "sims = torch.Tensor()\n",
    "cnt = 0\n",
    "for sample in tqdm(sample_lst):\n",
    "    word_lst = []\n",
    "    signal = -1\n",
    "    saves = []\n",
    "    for i, dep in enumerate(sample[:-1]):\n",
    "        word_lst.append(dep.word)\n",
    "        saves.append([dep.id, dep.word, dep.head, dep.rel])\n",
    "        \n",
    "        if dep.word in punct_lst and sample[i+1].word not in punct_lst:\n",
    "            x = prompt.split(' ') + ['[SEP]'] + word_lst\n",
    "            word_lst = []\n",
    "            signal1, signal2 = predict(x)\n",
    "            # preds = torch.cat([preds, torch.tensor([pred])], dim=0)\n",
    "            cnt += 1\n",
    "            for save in saves:\n",
    "                line = f'{save[0]}\\t{save[1]}\\t{signal1}\\t{signal2}\\t_\\t_\\t{save[2]}\\t{save[3]}\\t_\\t_\\n'\n",
    "                f.write(line)\n",
    "            saves = []\n",
    "    \n",
    "    if i + 1 < CFG.max_length and len(sample) > 0:\n",
    "        word_lst.append(sample[-1].word)\n",
    "        saves.append([sample[-1].id, sample[-1].word, sample[-1].head, sample[-1].rel])\n",
    "        \n",
    "        x = prompt.split(' ') + ['[SEP]'] + word_lst\n",
    "        signal1, signal2 = predict(x)\n",
    "        # preds = torch.cat([preds, torch.tensor([pred])], dim=0)\n",
    "        cnt += 1\n",
    "        for save in saves:\n",
    "            line = f'{save[0]}\\t{save[1]}\\t{signal1}\\t{signal2}\\t_\\t_\\t{save[2]}\\t{save[3]}\\t_\\t_\\n'\n",
    "            f.write(line)\n",
    "            \n",
    "    f.write('\\n')\n",
    "\n",
    "# print(preds.shape)\n",
    "print(cnt)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54e586e2-8cfe-439a-aa50-1349f8ca0205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def load_codt_signal(data_file: str):\n",
    "    sentence:List[Dependency] = []\n",
    "\n",
    "    with open(data_file, 'r', encoding='utf-8') as f:\n",
    "        # data example: 1\t上海\t_\tNR\tNR\t_\t2\tnn\t_\t_\n",
    "        for line in f.readlines():\n",
    "            toks = line.split()\n",
    "            if len(toks) == 0 and len(sentence) != 0:\n",
    "                yield sentence\n",
    "                sentence = []\n",
    "            elif len(toks) == 10:\n",
    "                signal = int(toks[2])\n",
    "                sentence.append(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d7e0823-2694-4706-9a9a-ac82e4aeae45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20086\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for sentence in load_codt_signal('/root/autodl-tmp/output.conll'):\n",
    "    cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfa8a1e9-8a0b-446f-9ab1-82b412a384cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20086\n"
     ]
    }
   ],
   "source": [
    "f = open('/root/autodl-tmp/output.conll', 'r', encoding='utf-8')\n",
    "\n",
    "cnt = 0\n",
    "for line in f.readlines():\n",
    "    if line == '\\n':\n",
    "        cnt += 1\n",
    "\n",
    "print(cnt)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0201e71b-7157-465e-bd26-308ccca0d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5029bdd-208b-4725-8279-411b41871db4",
   "metadata": {},
   "source": [
    "# Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "416dcfb3-f46e-4283-8a07-1e69e4da8336",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '能 表现 篇章 语义 信号 的 词 是 ： [MASK] [MASK] [MASK]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b9ec8fd-ea5d-4137-86db-21b76f455687",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '没有 付款'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3e1e5ef-0351-4e48-976b-8832060c96c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['说', '表示', '看到', '显示', '知道', '认为', '希望', '指出', '如果', '假如', '的话', '若', '如', '要是', '倘若', '因为', '所以', '导致', '因此', '造成', '由于', '因而', '但是', '可是', '但', '竟', '却', '不过', '居然', '而是', '反而', '以及', '并且', '或者', '对于', '自从', '上次', '明天', '晚上', '到时候', '再', '然后', '接下来', '最后', '随后', '为了', '使', '为 的', '为 了', '通过', '必须', '点击', '对 吗', '是 吗', '对 吧', '是 吧', '对 ?', '别 的', '另外', '解释', '比如', '例如', '是 这样', '理想', '真 棒', '太 棒', '真差', '太 差', '不 行', '扯皮', '这么 麻烦', '情况', '为什么', '吗', '?', '什么', '请', '麻烦', '让', '咨询']\n"
     ]
    }
   ],
   "source": [
    "id2signal = list(signal_dct.keys())\n",
    "print(id2signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "75835bcf-4697-48f4-a5a3-9874df360f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '没有', '付款']\n"
     ]
    }
   ],
   "source": [
    "word_lst = text.split(' ')\n",
    "x = prompt.split(' ') + ['[SEP]'] + word_lst\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1815281a-3e12-4be4-b6c0-cbc9b754edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal1, signal2 = predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9187f5c9-8c56-4ff3-9c41-580fd3f70389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 38)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal1, signal2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f58df7c-3737-4163-8bbd-85d97d45ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer.encode_plus(x, \n",
    "                                  padding='max_length', \n",
    "                                  truncation=True,\n",
    "                                  max_length=CFG.max_length, \n",
    "                                  return_offsets_mapping=True, \n",
    "                                  return_tensors='pt',\n",
    "                                  is_split_into_words=True)\n",
    "inputs_cuda = {}\n",
    "for key, value in tokenized.items():\n",
    "    if key != 'offset_mapping':\n",
    "        inputs_cuda[key] = value.cuda()\n",
    "tokenized = inputs_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5ab1bbac-fdc0-45de-a289-6fa156dd5da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_dct[labels[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eb4f8304-a14b-4eff-a96a-046a8a80aaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "117it [00:01, 84.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '亲亲', '您', '对', '我们', '的', '产品', '了解', '比较', '清楚', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "243it [00:02, 84.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '需要', '内存卡', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "558it [00:06, 81.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '没有', '的话', '，']\n",
      "25\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '没有', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "675it [00:07, 84.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '商家', '承诺', '了', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "738it [00:08, 84.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '后续', '商家', '未', '回复', '您', '的', '信息', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "873it [00:10, 77.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '修改', '不', '了', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '相距', '不', '远', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '不能', '修改', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1116it [00:13, 78.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '后续', '主', '商品', '收到', '可以', '给', '您', '申请', '补发', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '主产品', '收到', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1161it [00:13, 80.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '方便', '麻烦', '再', '确认', '一下', '。']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1863it [00:21, 100.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '不', '明白', '能', '否', '电话', '沟通', '?']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017it [00:23, 104.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '亲', '您', '暂时', '没', '什么', '问题', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2105it [00:24, 86.16it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '[', '数字', ']', '-', '[', '数字', ']', '天', '之间', '送达', '的', '哦', '海关', '清', '关', '速度', '快', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '咱们', '商品', '[', '数字', ']', '天', '内', '有', '质量', '问题', '可以', '售后', '提交', '退', '货', '申请', '的', '哦', '[', '数字', ']', '但是', '不是', '质量', '问题', '咱们', '是', '不', '支持', '的', '哦', '，']\n",
      "32\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '过', '了', '七', '天', '出', '问题', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2342it [00:26, 86.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '没有', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2477it [00:28, 83.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '到时候', '给', '我', '，']\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2495it [00:28, 81.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '注销', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2828it [00:32, 85.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '还', '有', '问题', '可以', '随时', '提问', '哦', '，']\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2972it [00:34, 83.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '的', '商品', '需要', '安装', '的话', '会', '在', '订单', '完成', '第二', '天', '我们', '的', '师傅', '上', '门', '为', '您', '安装', '哦', '~']\n",
      "25\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '的', '商品', '需要', '安装', '会', '在', '订单', '完成', '第二', '天', '我们', '的', '师傅', '上', '门', '为', '您', '安装', '哦', '~']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3332it [00:38, 78.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '取消', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3404it [00:39, 73.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '我', '不是', '会员', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '我', '不是', '会员', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '我', '那个', '那', '之前', '买', '那个', '退', '货', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3430it [00:39, 75.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '喜欢', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '这个', '屏幕', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3664it [00:42, 82.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '若', '您', '需要', '妹纸', '也', '可以', '将', '下', '单', ';']\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3772it [00:43, 81.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '今后', '再', '遇到', '什么', '疑问', '，']\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3799it [00:44, 77.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '确实', '不', '需要', '这', '款', '商品', '呢', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '不', '签收', '退', '款', '周期', '比较', '长', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '不', '签收', '退', '款', '周期', '比较', '长', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3897it [00:45, 82.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '商家', '收到', '您', '的', '取消', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3960it [00:46, 81.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '商品', '存在', '质量', '问题', '影响', '了', '您', '的', '正常', '使用', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4086it [00:47, 83.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '有', '活动', '都', '会', '在', '页面', '说明', '的', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '您', '还', '有', '问题', '可以', '随时', '提问', '哦', '，']\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4131it [00:48, 81.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '是', '男士', '的', '工作鞋', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '女士', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4491it [00:52, 84.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '要', '恢复', '订单', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '不', '成功', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '正常', '给', '您', '配送', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4707it [00:54, 84.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '年份', '调高至', '[', '数字', ']', '年会', '自动', '回', '到', '[', '数字', ']', '年', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4743it [00:55, 84.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '我', '这边', '有', '结果', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4896it [00:56, 85.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '还', '需要', '此', '商品', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4995it [00:58, 85.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '还', '有', '过敏', '现象', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5094it [00:59, 84.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '不是', '商品质量', '问题', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5202it [01:00, 84.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '拦截', '不', '成功', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '快递', '发', '过来', '了', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '快递', '来', '了', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5359it [01:01, 105.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '亲爱', '的', '距离', '远', '吗', '不是', '很', '远', '的话', '您', '希望', '送到', '哪里', '呢', '?']\n",
      "25\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '亲爱', '的', '距离', '远', '吗', '不是', '很', '远', '您', '希望', '送到', '哪里', '呢', '?']\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5453it [01:02, 108.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '今后', '再', '遇到', '什么', '疑问', '，']\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5588it [01:03, 107.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '延保', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5705it [01:05, 107.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '选择', '集中', '开', '票', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5716it [01:05, 104.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '原', '返', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5817it [01:06, 104.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '不', '方便', '签收', '可以', '和', '配送员', '协商', '下次', '送', '货', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '时间', '还是', '不', '合适', '可以', '和', '配送员', '协商', '下次', '送', '货', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5907it [01:06, 102.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '取消', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '这边', '确定', '取消', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6206it [01:09, 104.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '不', '看好', '京东', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6349it [01:11, 102.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '没有', '开', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '开', '的', '个人', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6481it [01:12, 105.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '京东', '配送', '速度', '也', '是', '比较', '快', '的', '需要', '建议', '及时', '购买', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6734it [01:14, 104.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '更改', '地址', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6855it [01:15, 102.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '你', '看', '能', '给', '我', '取消', '我', '重下', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '不能', '的话', '我', '到', '时', '可以', '收', '货', '，']\n",
      "25\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '不能', '我', '到', '时', '可以', '收', '货', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7331it [01:20, 107.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '申请', '退', '款', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7365it [01:20, 105.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '登录', '时', '输入', '用户名', '或', '手机号', '或', '邮箱', '(', '有', ')', '加上', '密码', '登录', '账户', '就', '可以', '了', '。']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '忘记', '密码', '可以', '点击', '忘记', '密码', '进行', '重置', '，']\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7453it [01:21, 102.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '还', '有', '问题', '可以', '随时', '提问', '哦', '，']\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7552it [01:22, 102.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '可以', '我', '就', '不', '取消', '了', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7585it [01:22, 101.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '麻烦', '查下', '这个', '订单', '的', '状态', '顾客', '还要', '继续', '派送', '行', '吗', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '这个', '解锁', '的话', '，']\n",
      "25\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '这个', '解锁', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '继续', '派送', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8195it [01:28, 100.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '想要', '的话', '，']\n",
      "25\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '想要', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '这', '款', '商品', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8228it [01:28, 103.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '还', '需要', '此', '商品', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8379it [01:30, 107.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '这样', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8401it [01:30, 106.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '我', '没有', '网线', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8547it [01:31, 106.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '放心', '确实', '有', '问题', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8646it [01:32, 107.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '—', '—', '点击', '应用', ')', '鼠标', '右', '[', '姓名', ']', '菜单', '没有', '“', 'NVIDIA', '”', '控制面板', '选项', '，']\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8712it [01:33, 104.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '商品', '存在', '质量', '问题', '影响', '了', '您', '的', '正常', '使用', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8735it [01:33, 104.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '拦截', '不', '成功', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '还', '有', '问题', '可以', '随时', '提问', '哦', '，']\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8802it [01:34, 106.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '师傅', '不', '上', '忙', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9029it [01:36, 106.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '我', '刚才', '的', '服务', '有', '不', '到位', '的', '地方', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9163it [01:37, 107.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '暂时', '没有', '其他', '的', '问题', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9450it [01:39, 107.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '确认', '收到', '了', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9550it [01:40, 102.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '还', '有', '什么', '问题', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9660it [01:41, 104.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '还', '有', '问题', '可以', '随时', '提问', '哦', '，']\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9836it [01:43, 103.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '暂时', '没有', '其他', '的', '问题', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9946it [01:44, 98.91it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '码数', '不', '合适', '语言', '换', '的话', '，']\n",
      "25\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '码数', '不', '合适', '语言', '换', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '那', '我', '签收', '了', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '不', '合适', '要', '换', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '我', '签收', '了', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '要', '退', '换', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '那', '要', '换', '的话', '，']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9967it [01:44, 94.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '那', '要', '换', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '我', '签收', '了', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10758it [01:52, 103.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '拦截', '不', '住', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '拦截', '不', '住', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10901it [01:53, 105.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '今后', '再', '遇到', '什么', '疑问', '，']\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10945it [01:53, 106.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '方便', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10967it [01:54, 102.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '新', '旧', '订单', '不', '一样', '的话', '，']\n",
      "25\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '新', '旧', '订单', '不', '一样', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11000it [01:54, 103.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '要是', '不', '想', '去', '实体店', '到', '货', '之后', '先', '不要', '安装', '，']\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11132it [01:55, 101.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '有', '就是', '可以', '修改', '的', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '没有', '就是', '系统', '已经', '处理', '了', '您', '的', '订单', '了', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11286it [01:57, 105.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '专票', '已经', '开具', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11330it [01:57, 105.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '订单', '签收', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11539it [01:59, 105.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '我', '想', '知道', '这个', '杯子', '有', '质量', '问题', '，']\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11605it [02:00, 104.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '以', '旧', '换', '新', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11682it [02:00, 101.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '我', '刚才', '的', '服务', '有', '不', '到位', '的', '地方', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11759it [02:01, 102.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '不', '会', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '有', '问题', '可以', '随时', '邮件', '到', '我', '的', '邮箱', ':']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11781it [02:01, 93.57it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '还', '有', '问题', '可以', '随时', '提问', '哦', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '的', '问题', '解决', '好', '了', '我', '就', '放心', '了', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '您', '还', '有', '问题', '可以', '随时', '提问', '哦', '，']\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12000it [02:04, 100.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '还', '有', '问题', '可以', '随时', '提问', '哦', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12153it [02:05, 100.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '的', '商品', '有', '发', '错', '货', '问题', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12296it [02:06, 103.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '退', '款', '商品', '返回', '咱们', '仓库', '给', '您', '审核', '处理', '的', '哦', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12428it [02:08, 100.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '没', '选', '的话', '，']\n",
      "25\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '没', '选', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12615it [02:10, 98.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '降', '价', '的话', '，']\n",
      "25\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '降', '价', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13212it [02:16, 82.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '可以', '恢复', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '那', '都', '退', '款', '完', '了', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '不', '退', '。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13230it [02:17, 79.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13842it [02:24, 77.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '只', '退', '十几块', '钱', '的话', '，']\n",
      "25\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '只', '退', '十几块', '钱', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13918it [02:25, 78.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '没有', '信号', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '这样', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14165it [02:28, 77.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '检测', '结果', '有', '差异', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14183it [02:28, 78.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '不是', '很', '远', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14210it [02:28, 79.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '余额', '返卡', '只', '可', '提', '现', '至', '储蓄卡', '(', '是', '支票', '支付', '、', '公司', '转账', '退', '款', '产生', '的', '余额', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14744it [02:35, 81.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '没', '办法', '选择', '京东', '配送', '后期', '邮寄', '售后', '处理', '处理完毕', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15104it [02:39, 73.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '实在', '没', '办法', '的话', '，']\n",
      "25\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '实在', '没', '办法', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '是', '抢购', '秒杀', '的话', '，']\n",
      "25\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '是', '抢购', '秒杀', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '这样', '建议', '您', '选购', '一下', '其他', '手机', '或者', '让', '亲戚朋友', '代收', '呢', '，']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15121it [02:39, 76.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15571it [02:45, 81.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '下', '单', '的', '时候', '没有', '选择', '的话', '，']\n",
      "25\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '下', '单', '的', '时候', '没有', '选择', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15598it [02:45, 74.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '的', '问题', '解决', '好', '了', '我', '就', '放心', '了', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '您', '还', '有', '问题', '可以', '随时', '提问', '哦', '，']\n",
      "25\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '还', '有', '问题', '可以', '随时', '提问', '哦', '，']\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15796it [02:47, 81.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '滤芯', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16489it [02:56, 83.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '有', '什么', '需要', '预约', '的', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16516it [02:56, 83.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '价格', '呢', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '魔兽', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16534it [02:56, 81.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '看中', '这个', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16606it [02:57, 84.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '没', '专员', '有', '货', '可以', '发', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16696it [02:58, 82.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '亲爱', '的', '不', '懂', '随时', '问', '妹子', '哦', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16822it [03:00, 83.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '客户', '要', '取消', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17029it [03:02, 82.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '恢复', '订单', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '有', '什么', '问题', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17056it [03:02, 79.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '有', '什么', '问题', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '哪', '有', '有', '问题', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17235it [03:04, 86.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '通过', '微信', '支付', '，']\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17298it [03:05, 83.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '购买', '商品', '[', '数字', ']', '天', '内', '降', '价', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17325it [03:06, 82.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '确实', '不', '需要', '这', '款', '商品', '呢', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '不', '签收', '退', '款', '周期', '比较', '长', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17388it [03:06, 85.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '送', '货', '地点', '暂时', '无法', '进入', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17514it [03:08, 95.75it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '问题', '解决', '好', '了', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '您', '还', '有', '问题', '可以', '随时', '提问', '哦', '，']\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17652it [03:09, 92.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '是', '零钱', '支付', '的', '，']\n",
      "27\n",
      "['能', '表现', '篇章', '语义', '信号', '的', '词', '是', '：', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '银行卡', '，']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17670it [03:09, 93.10it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_756/4239077190.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'[SEP]'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mword_lst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0msignal1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_756/1736671667.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_756/622417942.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, labels)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mmasked_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# batch_size, masked_len, plm_hidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_feats\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# batch_size, masked_len, vocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "targets = targets.view(targets.size()[0], -1).T.cuda()\n",
    "sims = torch.Tensor()\n",
    "cnt = 0\n",
    "for sample, label in tqdm(zip(sample_lst, labels)):\n",
    "    word_lst = []\n",
    "    signal = -1\n",
    "    saves = []\n",
    "    for i, dep in enumerate(sample[:-1]):\n",
    "        word_lst.append(dep.word)\n",
    "        saves.append([dep.id, dep.word, dep.head, dep.rel])\n",
    "        \n",
    "        if dep.word in punct_lst and sample[i+1].word not in punct_lst:\n",
    "            x = prompt.split(' ') + ['[SEP]'] + word_lst\n",
    "            # for w in ['但是', '但', '可是', '却']:\n",
    "            for w in ['如果', '的话', '假如']:\n",
    "                if w in x:\n",
    "                    x.remove(w)\n",
    "                    print(x)\n",
    "                    signal1, signal2 = predict(x)\n",
    "                    print(signal1)\n",
    "            cnt += 1\n",
    "            saves, word_lst = [], []\n",
    "    \n",
    "    if i + 1 < CFG.max_length and len(sample) > 0:\n",
    "        word_lst.append(sample[-1].word)\n",
    "        saves.append([sample[-1].id, sample[-1].word, sample[-1].head, sample[-1].rel])\n",
    "        \n",
    "        x = prompt.split(' ') + ['[SEP]'] + word_lst\n",
    "        signal1, signal2 = predict(x)\n",
    "        \n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2eab4a-e1a7-4705-8ff2-fb0db184f75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f5970cc3159b15dedb1f3a2bddfb758e67a1721376b7397fa1f3df8941c2f173"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
